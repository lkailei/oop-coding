---
title : 面试题目
tag : interview
---



### 基础技能

java面向对象的思想（封装，继承，多态，重载，重写，接口，抽象类）

String不可变？

StringBuffer和StringBuild区别，

常量池

关键字：serializable，wait()

transient有什么作用(序列化)

介绍一下集合

ArrayList和LinkedList,Vector

Hash表的实现原理

Hash表如何解决冲突

HashMap和HashSet的区别

HashMap和HashTable的区别

HashMap的底层原理

HashMap为何初始容量为16

HashMap初始化为18是如何扩容的

HashMap的线程安全问题

ConcurrentHashMap的原理

List Map Set

线程与进程

多线程是什么

java启动线程的方式

线程池原理，有什么好处

线程的状态,可达状态

线程类中的方法sleep(),yield() wait() notify() run() start()

线程安全，如何实现线程安全

集合中的线程安全如何保证

锁

synchronized的可重入怎么实现

synchronized和Lock

死锁的四个条件，如何破坏死锁

关键字：Volatile(保证有序性可见性),final,synchronized

反射

jvm垃圾回收机制

类加载过程

单例模式优缺点

单例模式的实现(饿汉式，懒汉式)

工厂模式

动态代理

装饰者模式

常用的排序及其实现(冒泡，选择，快排，插入)

Linux的命令

Http协议

TCP与UDP

TCP三次握手与四次挥手，

TCP为何不是两次握手，

Tcp建立连接，但客户端出现故障怎么办。

### 数据库技能（sql&nosql）

mysql语句，增删改查，能够说出来

mysql查询优化

mysql索引优化(索引失效的情况)

mysql存储过程

mysql如何看是否走索引

数据库事务ACID

数据库事务隔离级别

数据库事务脏读，幻读，不可重复读

Redis的数据类型

Redis主要作用

Redis 缓存穿透(有key但是无value)，缓存击穿（数据库有），缓存雪崩

Redis分布式锁

Redis持久化策略 AOF 与RDB

Redis的数据删除策略（定时删除，定期删除，惰性删除）

Redis的数据逐出策略

Redis的并发竞争key

Redis与数据库双写不一致

Redis同步机制

Redis过期时间和永久有效怎么设置

Redis如何做内存优化

### JavaEE技能

request作用

session与cookie

Servlet调用过程

谈谈Spring

Spring IOC

Spring AOP原理

Spring Bean的生命周期

Spring Bean DI

Spring 依赖注入的方式

Spring的注解 @Autowried @Resource 

Spring MVC执行流程

Spring事务级别默认事务级别

Spring Boot

ORM框架(jdbc template)

mybatis是什么

mybatis的创建过程

mybatis中的#{}与${}  (预编译，sql注入)

mybatis 中的like

Spring Boot与Spring Cloud

Spring Cloud的组件

Dubbo与Zookeeper

Dubbo协议

Dubbo注册中心，对象序列化方式

CAS

euraka,zookeeper,consul区别

Zookeeper选举策略(CP)

Eureka选举策略（AP）

Zookeeper分布式锁

rabbitMQ和activeMQ如何在项目中的使用

### 其他

docker 

nginx

nginx的负载均衡策略

JUC 并发编程

### Java基础&高级

#### 基本类型常见的面试题：

##### Q&A 什么是自动装箱与拆箱？

自动装箱就是java编译器在基本数据类型和对应的对象包装类型之间做一个转化，比如int转为Integer,double转为Double.反之为自动拆箱。

##### Q&A String是基本的数据类型吗？

String不是节本的数据类型，是final不可修改的类，为了提高效率可以使用StringBuffer类。

##### Q&A int 和integer有什么区别？

int是基本类型，integer是包装类型。

integer必须实例化后才能使用，而int变量不需要。

integer默认为null,而int默认为0；

integer实际是对象的引用，当new出一个integer时实际上是生成一个指针指向此对象，而int则是直接存储数据值。

##### Q&A 以下结果是什么？

```java
Integer a= new Integer(3);
Integer b= 3; // 将3 自动装箱为Integer类型
int c=3;
a==b  // false 两个引用没有引用统一对象。
a==c // true a 自动 拆箱为int 再和c 比较。
两个非new生成的integer对象，进行比较时如果两个变量值的区间在-128~127之间则比较为 true,如果不在此区间则为false;
Integer a=100;  => Integer a = Integer.valueOf(100);
Integer b=100;
a==b // true;
Integer a=128;
Integer b=128;
a== b // false;
对于valueOf方法在Integer类中会有一个cache判断：

```

##### Q&A  short s1 = 1; s1 = s1 + 1;有什么错? short s1 = 1; s1 +=1;有什么错?

1) 对于 shorts1=1;s1=s1+1 来说，在s1+1 运算时会自动提升表达式的类型为 int， 那么将int赋予给 short类型的变量 s1会出现类型转换错误。
2) 对于 short s1=1;s1+=1 来说 +=是java 语言规定的运算符，java 编译器会对它 进行特殊处理，因此可以正确编译。

##### Q&A String的不可变性

```java
Strings are constant; their values cannot be changed after theyare created. String buffers support mutable strings.Because String objects are immutable they can be shared. 
    For example:
 String str = "abc";
 与下面的相等;
 *     char data[] = {'a', 'b', 'c'};
 *     String str = new String(data);
 * Here are some more examples of how strings can be used:
 * <blockquote><pre>
 *     System.out.println("abc");
 *     String cde = "cde";
 *     System.out.println("abc" + cde);
 *     String c = "abc".substring(2,3);
 *     String d = cde.substring(1, 2);
 * </pre></blockquote>
 * <p>
```

##### Q&A **为何String设计为不可变？**

1、运行时常量池的需要,节省内存空间。

　　比如执行 String s = "abc";执行上述代码时，JVM首先在运行时常量池中查看是否存在String对象“abc”，如果已存在该对象，则不用创建新的String对象“abc”，而是将引用s直接指向运行时常量池中已存在的String对象“abc”；如果不存在该对象，则先在运行时常量池中创建一个新的String对象“abc”，然后将引用s指向运行时常量池中创建的新String对象。这样在运行时常量池中只会创建一个String对象"abc"，这样就节省了内存空间。

2、同步

　　因为String对象是不可变的，所以是多线程安全的，同一个String实例可以被多个线程共享。这样就不用因为线程安全问题而使用同步。

3、允许String对象缓存hashcode

　　查看上文JDK1.8中String类源码，可以发现其中有一个字段hash，String类的不可变性保证了hashcode的唯一性，所以可以用hash字段对String对象的hashcode进行缓存，就不需要每次重新计算hashcode。所以Java中String对象经常被用来作为HashMap等容器的键。

4、安全性

　　如果String对象是可变的，那么会引起很严重的安全问题。比如，数据库的用户名、密码都是以字符串的形式传入来获得数据库的连接，或者在socket编程中，主机名和端口都是以字符串的形式传入。因为String对象是不可变的，所以它的值是不可改变的，否则黑客们可以钻到空子，改变String引用指向的对象的值，造成安全漏洞。

##### Q&A  **String s = new String("xyz");创建了几个String Object?二者之间有什么区别？**

两个或一个，”xyz”对应一个对象，这个对象放在字符串常量缓冲区，常量”xyz”不管出现多少遍，都是缓冲区中的那一个。New String每写一遍，就创建一个新的对象，它一句那个常量”xyz”对象的内容来创建出一个新String对象。如果以前就用过’xyz’，这句代表就不会创建”xyz”自己了，直接从缓冲区拿。

##### Q&A 创建对象的方法：

1.使用new关键字。

2.使用Class类中的newInstance方法，newInstance方法调用无参构造方器创建对象。Class.forName.newInstance;

3.使用clone方法、

4.反序列化。

##### Q&A 对象的产生过程以及存储：

对象的产生：

new将对象存储在堆中，所以用new创建一个对象---特别小的，简单的变量，往往不是很有效。因此对于（基本类型）java不用new来创建这样的变量，而是创建一个并非是引用的“自动”变量。这个变量的值直接存储"值"到堆栈中。

![](https://upload-images.jianshu.io/upload_images/4748730-7942afd5d21fe639.jpg?imageMogr2/auto-orient/strip|imageView2/2/format/webp)

程序创建，运行时对象是如何分配呢？内存是怎样分配呢？

![dnZRHO.jpg](https://s1.ax1x.com/2020/08/17/dnZRHO.jpg)

对象产生的时机 类加载，然后进行对象的实例化：

##### Q&A **什么时候会进行类加载？**

1.创建类的实例，也就是new一个对象

2.访问某个类或接口的静态变量，或者对该静态变量赋值

3.调用类的静态方法

4.反射（Class.forName("A")）

5.初始化一个类的子类（会首先初始化子类的父类）

6.JVM启动时标明的启动类，即文件名和类名相同的那个类

new ObjectInitTest（）对象的产生过程

1.JVM会在ObjectInitTest.class文件
2.先加载类级别的成员（静态成员变量 静态块初始化）
3.再加载对象级别的成员（实例成员变量 实例块初始化）

##### Q&A**什么时候进行对象的实例化？**

类加载成功（或已加载过）后，就开始进行对象的实例化了。对象的实例化依次进行了如下几个步骤：

1.对象在堆中的内存空间分配

2.初始化零值，这时会将实例变量都赋予零值

3.设置对象头，对象头保存了一些对象在运行期的状态信息，包括类信息地址（知道对象是属于哪个类的）、hashcode（用于HashMap和hashset等hash结构中）、GC分代年龄（可以依此确定对象何时该放入老年代）等

4.init方法执行，这时对变量的实例变量进行初始化

对象初始化的过程也是线程安全的动作。

#####  Q&A StringBuffer StringBulider String 的区别：

StringBuffer线程安全，StringBulider线程不安全，底层实现StringBuffer比StringBulider多一个Synchronized.从源码中可以看得到：

```java
StringBuffer源码分析：
	@Override
    public synchronized int length() {
        return count;
    }

    @Override
    public synchronized int capacity() {
        return value.length;
    }

    @Override
    public synchronized void ensureCapacity(int minimumCapacity) {
        if (minimumCapacity > value.length) {
            expandCapacity(minimumCapacity);
        }
    }

    /**
     * @since      1.5
     */
    @Override
    public synchronized void trimToSize() {
        super.trimToSize();
    }

    /**
     * @throws IndexOutOfBoundsException {@inheritDoc}
     * @see        #length()
     */
    @Override
    public synchronized void setLength(int newLength) {
        toStringCache = null;
        super.setLength(newLength);
    }

    /**
     * @throws IndexOutOfBoundsException {@inheritDoc}
     * @see        #length()
     */
    @Override
    public synchronized char charAt(int index) {
        if ((index < 0) || (index >= count))
            throw new StringIndexOutOfBoundsException(index);
        return value[index];
    }
```

##### Q&A String 是否可以继承，“+”如何实现的，与StringBuffer区别？

java中通过使用“+”符号串联时实际是使用的StringBuilder实例的appdend()方法来实现的。

#### 初始化与清理常见的面试题：

##### Q&A :java 对象加载初始化的顺序？

静态代码块--》非静态代码块-（静态代码块（只有一次），构造函数）-》构造函数，而{}包含的非静态代码块就是和构造方法一样会默认初始化

##### Q&A: :如何判断一个对象是否要回收？

这就是所谓的对象存活性判断，常用的方法有两种：1.引用计数法;　2.对象可达性分析。由于引用计数法存在互相引用导致无法进行GC的问题，所以目前JVM虚拟机多使用对象可达性分析算法。从GC Roots对象计算引用链，能链上的就是存活的。

1、引用计数法

引用计数法的逻辑非常简单，但是存在问题，java并不采用这种方式进行对象存活判断。

引用计数法的逻辑是：在堆中存储对象时，在对象头处维护一个counter计数器，如果一个对象增加了一个引用与之相连，则将counter++。如果一个引用关系失效则counter–。如果一个对象的counter变为0，则说明该对象已经被废弃，不处于存活状态。

2、可达性分析算法

在主流的商用程序语言中(Java和C#)，都是使用可达性分析算法判断对象是否存活的。这个算法的基本思路就是通过一系列名为GC Roots的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链(Reference Chain)，当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的，下图对象object5, object6, object7虽然有互相判断，但它们到GC Roots是不可达的，所以它们将会判定为是可回收对象。

![](https://img-blog.csdnimg.cn/20190529111953162.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyOTk2NzYx,size_16,color_FFFFFF,t_70)

参看：https://blog.csdn.net/qq_42996761/article/details/90667725

##### Q&A 如何理解java中的垃圾回收机制？为什么需要垃圾回收机制？

java采用分代回收，分为年轻代、老年代、永久代。年轻代又分为E区、S1区、S2区。

到jdk1.8，永久代被元空间取代了。

年轻代都使用复制算法，老年代的收集算法看具体用什么收集器。默认是PS收集器，采用标记-整理算法。

System.gc()即垃圾收集机制是指jvm用于释放那些不再使用的对象所占用的内存。垃圾收集的目的在于清除不再使用的对象。gc通过确定对象是否被活动对象引用来确定是否收集该对象。
如果你向系统申请分配内存进行使用(new)，可是使用完了以后却不归还(delete)，结果你申请到的那块内存你自己也不能再访问,该块已分配出来的内存也无法再使用，随着服务器内存的不断消耗，而无法使用的内存越来越多，系统也不能再次将它分配给需要的程序，产生泄露。一直下去，程序也逐渐无内存使用，就会溢出。

##### Q&A java垃圾收集的方式有哪些？

上文已经讲述。

##### Q&A java垃圾回收机制的优缺点？

优点：

开发人员无须过多地关心内存管理，而是关注解决具体的业务。虽然内存泄漏在技术上仍然是可能出现的，但不常见。

GC 在管理内存上有很多智能的算法，它们自动在后台运行。与流行的想法相反，这些通常比手动回收更能确定什么时候是执行垃圾回收的最好时机。

缺点：

当垃圾回收发生时将影响程序的性能，显著地降低运行速度甚至将程序停止。所谓 “Stop the world” 就是当垃圾回收发生的时候应用程序的其他任务都将被冻结。对于应用程序的要求来说，这将是不可接收的，虽然 GC 调优可以最小化甚至消除这个影响。

虽然GC有很多方面可以调优，但你不能指定应用程序在何时怎样执行GC

##### Q&A java垃圾回收的时间有哪些？

CPU空闲时进行回收、堆内存满了后进行回收、调用System.gc()回收。

##### Q&A 如果对象置为null，垃圾收集器是否会立即释放占用的内存？

不会。对象回收需要一个过程，这个过程中对象还能复活。而且垃圾回收具有不确定性，指不定什么时候开始回收。

##### Q&A 什么是GC？为何有GC?

GC就是垃圾收集的意思（Gabage Collection）。我们在开发中会创建很多对象，这些对象一股脑的都扔进了堆里，如果这些对象只增加不减少，那么堆空间很快就会被耗尽。所以我们需要把一些没用的对象清理掉。jvm使用 jstat -gc 12538 5000   即会每5秒一次显示进程号为12538的java进成的GC情况.

##### Q&A 方法区如何判断是否需要回收？

方法区主要回收的内容有：废弃常量和无用的类。对于废弃常量也可通过引用的可达性来判断，但是对于无用的类则需要同时满足下面3个条件：
① 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例；
② 加载该类的ClassLoader已经被回收；
③ 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。

##### Q&A 如果频繁老年代回收怎么分析解决？

```
老年代频繁回收，一般是Full GC，Full GC 消耗很大，因为在所有用户线程停止的情况下完成回收，而造成频繁 Full GC 的原因可能是，程序存在问题，或者环境存在问题。
对jvm的GC进行必要的监控，操作如下：
1、使用jps命令（或者ps -eaf|grep java）获取到当前的java进程（取得进程id，假如pid为 1234）
2、使用jstat查看GC情况（如：jstat -gc 1234 1000，后面的1000表示每个1000毫米打印一次监控），jstat命令可以参考：https://www.cnblogs.com/yjd_hycf_space/p/7755633.html （此文使用的是jdk8，但是本人亲测jstat在jdk7也是这样的）
jstat -class pid:显示加载class的数量，及所占空间等信息。 
jstat -compiler pid:显示VM实时编译的数量等信息。 
jstat -gc pid:可以显示gc的信息，查看gc的次数，及时间。其中最后五项，分别是young gc的次数，young gc的时间，full gc的次数，full gc的时间，gc的总时间。 
jstat -gccapacity:可以显示，VM内存中三代（young,old,perm）对象的使用和占用大小，如：PGCMN显示的是最小perm的内存使用量，PGCMX显示的是perm的内存最大使用量，PGC是当前新生成的perm内存占用量，PC是但前perm内存占用量。其他的可以根据这个类推， OC是old内纯的占用量。 
jstat -gcnew pid:new对象的信息。 
jstat -gcnewcapacity pid:new对象的信息及其占用量。 
jstat -gcold pid:old对象的信息。 
jstat -gcoldcapacity pid:old对象的信息及其占用量。 
jstat -gcpermcapacity pid: perm对象的信息及其占用量。 
jstat -util pid:统计gc信息统计。 
jstat -printcompilation pid:当前VM执行的信息。 
除了以上一个参数外，还可以同时加上 两个数字，如：jstat -printcompilation 3024 250 6是每250毫秒打印一次，一共打印6次，还可以加上-h3每三行显示一下标题
3、使用jmap（jmap 是一个可以输出所有内存中对象的工具）导出对象文件。如对于java进程（pid=1234），可以这样：jmap -histo 1234 > a.log 将对象导出到文件，然后通过查看对象内存占用大小，返回去代码里面找问题。
（也可以使用命令，导出对象二进制内容（这样导出内容比jmap -histo多得多，更耗时，对jvm的消耗也更大）：jmap -dump:format=b,file=a.log 1234）
```

#### 集合常见的面试题：

##### Q&A HashMap的组成？

jdk 1.7时是数组+链表组成，

jdk1.8时是 数组+ 链表 + 红黑树组成。 链表元素大于等于8时会把链表转为树结构，若桶中链的元素个数小于等于6时，树结构还原成链表。当链表的个数为8左右徘徊时就会生成树转链表，链表转树，效率低下。hasMap的负载因子默认为0.75，2^n是为了散列更加均匀。

##### Q&A HashMap的key为自定义的类应该怎么办？

如果key为自定义的类应该重写hashcode()和equals()方法。

##### Q&A HashMap为何线程不安全？

1.在JDK1.7中，当并发执行扩容操作时会造成环形链和数据丢失的情况。
2.在JDK1.8中，在并发执行put操作时会发生数据覆盖的情况。

##### Q&A HashMap如何保证线程安全？

使用Collections.synchronizedMap()包装一下就可以了，原理就是对所有的修改操作都加上synchronized，保证了线程的安全。

```java
Map  map = Collections.synchronizedMap(new HashMap());
```

##### Q&A HashMap中的key可以为任意类型吗？

不能使用基本类型，HashMap中key是可以为null, 只能存储一个null, 因为计算key的hash值的时候，如果key为null， 则其hash值为0

之所以key不能为基本数据类型，则是因为基本数据类型不能调用其hashcode()方法和equals()方法，进行比较，所以HashMap集合的key只能为引用数据类型，不能为基本数据类型，可以使用基本数据类型的包装类，例如Integer Double等。

##### Q&A HashMap的工作原理？

HashMap 底层是 hash 数组和单向链表实现，数组中的每个元素都是链表，由 Node 内部类（实现 Map.Entry<K,V>接口）实现，HashMap 通过 put & get 方法存储和获取。

存储对象时，将 K/V 键值传给 put() 方法：

①、调用 hash(K) 方法计算 K 的 hash 值，然后结合数组长度，计算得数组下标；

②、调整数组大小（当容器中的元素个数大于 capacity * loadfactor 时，容器会进行扩容resize 为 2n）；

③、 i.如果 K 的 hash 值在 HashMap 中不存在，则执行插入，若存在，则发生碰撞；

ii.如果 K 的 hash 值在 HashMap 中存在，且它们两者 equals 返回 true，则更新键值对；

iii. 如果 K 的 hash 值在 HashMap 中存在，且它们两者 equals 返回 false，则插入链表的尾部（尾插法）或者红黑树中（树的添加方式）。

> （JDK 1.7 之前使用头插法、JDK 1.8 使用尾插法）
> （注意：当碰撞导致链表大于 TREEIFY_THRESHOLD = 8 时，就把链表转换成红黑树）

获取对象时，将 K 传给 get() 方法：①、调用 hash(K) 方法（计算 K 的 hash 值）从而获取该键值所在链表的数组下标；②、顺序遍历链表，equals()方法查找相同 Node 链表中 K 值对应的 V 值。

hashCode 是定位的，存储位置；equals是定性的，比较两者是否相等

##### Q&A HashMap中的hashcode相同会怎么样？

因为 hashCode 相同，不一定就是相等的（equals方法比较），所以两个对象所在数组的下标相同，"碰撞"就此发生。又因为 HashMap 使用链表存储对象，这个 Node 会存储到链表中。

##### Q&A 你知道 hash 的实现吗？为什么要这样实现？

JDK 1.8 中，是通过 hashCode() 的高 16 位异或低 16 位实现的：(h = k.hashCode()) ^ (h >>> 16)，主要是从速度，功效和质量来考虑的，减少系统的开销，也不会造成因为高位没有参与下标的计算，从而引起的碰撞。

##### Q&A 为什么hash实现要用异或运算

保证了对象的 hashCode 的 32 位值只要有一位发生改变，整个 hash() 返回值就会改变。尽可能的减少碰撞。

##### Q&A HashMap的table的容量如何确定？loadFactor是什么？**该容量如何变化？这种变化会带来什么问题？**

- table 数组大小是由 capacity 这个参数确定的，默认是16，也可以构造时传入，最大限制是1<<30；

- loadFactor 是装载因子，主要目的是用来确认table 数组是否需要动态扩展，默认值是0.75，比如table 数组大小为 16，装载因子为 0.75 时，threshold 就是12，当 table 的实际大小超过 12 时，table就需要动态扩容；

- 扩容时，调用 resize() 方法，将 table 长度变为原来的两倍（注意是 table 长度，而不是 threshold）

- 如果数据很大的情况下，扩展时将会带来性能的损失，在性能要求很高的地方，这种损失很可能很致命。


##### Q&A HashMap中put方法的过程？

“调用哈希函数获取Key对应的hash值，再计算其数组下标；

- 如果没有出现哈希冲突，则直接放入数组；如果出现哈希冲突，则以链表的方式放在链表后面；
- 如果链表长度超过阀值( TREEIFY THRESHOLD==8)，就把链表转成红黑树，链表长度低于6，就把红黑树转回链表;
- 如果结点的key已经存在，则替换其value即可；
- 如果集合中的键值对大于12，调用resize方法进行数组扩容。”

##### Q&A hashMap中的数组扩容过程？

创建一个新的数组，其容量为旧数组的两倍，并重新计算旧数组中结点的存储位置。结点在新数组中的位置只有两种，原下标位置或原下标+旧数组的大小。

##### Q&A 拉链法导致的链表过深问题为什么不用二叉查找树代替，而选择红黑树？为什么不一直使用红黑树？

之所以选择红黑树是为了解决二叉查找树的缺陷，二叉查找树在特殊情况下会变成一条线性结构（这就跟原来使用链表结构一样了，造成很深的问题），遍历查找会非常慢。

而红黑树在插入新数据后可能需要通过左旋，右旋、变色这些操作来保持平衡，引入红黑树就是为了查找数据快，解决链表查询深度的问题，我们知道红黑树属于平衡二叉树，但是为了保持“平衡”是需要付出代价的，但是该代价所损耗的资源要比遍历线性链表要少，所以当长度大于8的时候，会使用红黑树，如果链表长度很短的话，根本不需要引入红黑树，引入反而会慢。

##### Q&A 说说你对红黑树的见解？

1、每个节点非红即黑

2、根节点总是黑色的

3、如果节点是红色的，则它的子节点必须是黑色的（反之不一定）

4、每个叶子节点都是黑色的空节点（NIL节点）

5、从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）

##### Q&A  jdk8中对HashMap做了哪些改变？

在java 1.8中，如果链表的长度超过了8，那么链表将转换为红黑树。（桶的数量必须大于64，小于64的时候只会扩容）

发生hash碰撞时，java 1.7 会在链表的头部插入，而java 1.8会在链表的尾部插入

在java 1.8中，Entry被Node替代(换了一个马甲)。

##### Q&A HashMap，LinkedHashMap，TreeMap 有什么区别？

- HashMap 参考其他问题；
- LinkedHashMap 保存了记录的插入顺序，在用 Iterator 遍历时，先取到的记录肯定是先插入的；遍历比 HashMap 慢；
- TreeMap 实现 SortMap 接口，能够把它保存的记录根据键排序（默认按键值升序排序，也可以指定排序的比较器）

##### Q&A HashMap & TreeMap & LinkedHashMap 使用场景？

一般情况下，使用最多的是 HashMap。

- HashMap：在 Map 中插入、删除和定位元素时；
- TreeMap：在需要按自然顺序或自定义顺序遍历键的情况下；
- LinkedHashMap：在需要输出的顺序和输入的顺序相同的情况下。

##### Q&A HashMap 和 HashTable 区别?

- HashMap和HashTable都实现了Map接口，
- HashMap允许键和值是null而HashTable不允许键和值是null,
- HashTable是同步的，而HashMap不是，因此hashMap适用于单线程环境，而HashTable适用于多线程环境。
- HashMap提供了可供应用迭代的键的集合.HashMap默认初始化数组的大小为16，HashTable的为11，HashMap扩容为扩容为2倍，HashTable为扩容为2倍+1.
- HashMap需要从新计算hash值，而HashTable直接使用的是对象的hashCode。

##### Q&A HashMap和ConCurrentHashMap区别？

hashMap线程不安全，put时在多线程的情况下会形成环而导致循环。

HashMap的键值对允许有null但ConCurrentHashMap都不允许。

ConCurrentHashMap是线程安全的，采用分段机制，减少锁粒度。

ConCurrentHashMap是线程安全，在jdk1.7时采用Segment+HashEntry的方式进行实现 lock加上Segment上面。1.7 size计算是线采用不加锁的方式。连续计算元素的个数，最多计算3次。

1.8中取而代之是采用Node+CAS +Synchronized来保证并发安全，1.8实现使用一个volatile类型的变量baseCount记录元素的各少数。当插入新数据或删除新数据时，会通过addCount()方法更新baseCount，通过累计baseCount和CounterCell数组中的数量，即可得到元素的总个数。

##### Q&A ConcurrentHashMap 和 HashTable 区别?

**ConcurrentHashMap**

- 底层采用分段的数组+链表实现，线程**安全**
- 通过把整个Map分为N个Segment，可以提供相同的线程安全，但是效率提升N倍，默认提升16倍。(读操作不加锁，由于HashEntry的value变量是 volatile的，也能保证读取到最新的值。)
- Hashtable的synchronized是针对整张Hash表的，即每次锁住整张表让线程独占，ConcurrentHashMap允许多个修改操作并发进行，其关键在于使用了锁分离技术
- 有些方法需要跨段，比如size()和containsValue()，它们可能需要锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁
- 扩容：段内扩容（段内元素超过该段对应Entry数组长度的75%触发扩容，不会对整个Map进行扩容），插入前检测需不需要扩容，有效避免无效扩容

**HashTable**

- 底层数组+链表实现，无论key还是value都**不能为null**，线程**安全**，实现线程安全的方式是在修改数据时锁住整个HashTable，效率低，ConcurrentHashMap做了相关优化
- 初始size为**11**，扩容：newsize = olesize*2+1
- 计算index的方法：index = (hash & 0x7FFFFFFF) % tab.length

两则的区别：

hashtable线程安全，采用的是线程同步得方法。

- ConcurrentHashMap提供了与Hashtable和SynchronizedMap不同的锁机制。Hashtable中采用的锁机制是一次锁住整个hash表，从而在同一时刻只能由一个线程对其进行操作；而ConcurrentHashMap中则是一次锁住一个桶。

- Java5提供了ConcurrentHashMap，它是HashTable的替代，比HashTable的扩展性更好。

##### Q&A 为什么ConcurrentHashMap比HashTable效率高

HashTable使用的是一把锁（锁住整个链表结构）处理并发问题，多个线程竞争一把锁，容易阻塞。

ConcurrentHashMap

- JDK 1.7 中使用分段锁（ReentrantLock + Segment + HashEntry），相当于把一个 HashMap 分成多个段，每段分配一把锁，这样支持多线程访问。锁粒度：基于 Segment，包含多个 HashEntry。
- JDK 1.8 中使用 CAS + synchronized + Node + 红黑树。锁粒度：Node（首结点）（实现 Map.Entry<K,V>）。锁粒度降低了。

JDK 1.7 中，采用分段锁的机制，实现并发的更新操作，底层采用数组+链表的存储结构，包括两个核心静态内部类 Segment 和 HashEntry。

- Segment 继承 ReentrantLock（重入锁） 用来充当锁的角色，每个 Segment 对象守护每个散列映射表的若干个桶；
- HashEntry 用来封装映射表的键-值对；
- 每个桶是由若干个 HashEntry 对象链接起来的链表

JDK 1.8 中，采用Node + CAS + Synchronized来保证并发安全。取消类 Segment，直接用 table 数组存储键值对；当 HashEntry 对象组成的链表长度超过 TREEIFY_THRESHOLD 时，链表转换为红黑树，提升性能。底层变更为数组 + 链表 + 红黑树

##### Q&A ConcurrentHashMap 在 JDK 1.8 中，为什么要使用内置锁 synchronized 来代替重入锁 ReentrantLock？

- 锁粒度降低了；
- JVM 开发团队没有放弃 synchronized，而且基于 JVM 的 synchronized 优化空间更大，更加自然。
- 在大量的数据操作下，对于 JVM 的内存压力，基于 API 的 ReentrantLock 会开销更多的内存。

##### Q&A ConcurrentHashMap简单介绍

①、重要的常量：

- private transient volatile int sizeCtl;
- 当为负数时，-1 表示正在初始化，-N 表示 N - 1 个线程正在进行扩容；
- 当为 0 时，表示 table 还没有初始化；
- 当为其他正数时，表示初始化或者下一次进行扩容的大小。

②、数据结构：

- Node 是存储结构的基本单元，继承 HashMap 中的 Entry，用于存储数据；
- TreeNode 继承 Node，但是数据结构换成了二叉树结构，是红黑树的存储结构，用于红黑树中存储数据；
- TreeBin 是封装 TreeNode 的容器，提供转换红黑树的一些条件和锁的控制。

③、存储对象时（put() 方法）：

- 如果没有初始化，就调用 initTable() 方法来进行初始化；
- 如果没有 hash 冲突就直接 CAS 无锁插入；
- 如果需要扩容，就先进行扩容；
- 如果存在 hash 冲突，就加锁来保证线程安全，两种情况：一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入；
- 如果该链表的数量大于阀值 8，就要先转换成红黑树的结构，break 再一次进入循环
- 如果添加成功就调用 addCount() 方法统计 size，并且检查是否需要扩容。

④、扩容方法 transfer()：默认容量为 16，扩容时，容量变为原来的两倍。

- helpTransfer()：调用多个工作线程一起帮助进行扩容，这样的效率就会更高。

⑤、获取对象时（get()方法）：

- 计算 hash 值，定位到该 table 索引位置，如果是首结点符合就返回；
- 如果遇到扩容时，会调用标记正在扩容结点 ForwardingNode.find()方法，查找该结点，匹配就返回；
- 以上都不符合的话，就往下遍历结点，匹配就返回，否则最后就返回 null。

##### Q&A ConcurrentHashMap的并发度是多少

程序运行时能够同时更新ConcurrentHashMap 且不产生锁竞争的最大线程数。默认为 16，且可以在构造函数中设置。当用户设置并发度时，ConcurrentHashMap 会使用大于等于该值的最小2幂指数作为实际并发度（假如用户设置并发度为17，实际并发度则为32）

##### Q&A LinkedHashMap 与 HashMap 的区别?

**HashMap**

- HashMap 是一个最常用的Map，它根据键的HashCode 值存储数据，根据键可以直接获取它的值，具有很快的访问速度。遍历时，取得数据的顺序是完全随机的。
- HashMap最多只允许一条记录的键为Null；允许多条记录的值为 Null。
- HashMap不支持线程的同步（即任一时刻可以有多个线程同时写HashMap），可能会导致数据的不一致。如果需要同步，可以用 Collections的synchronizedMap方法使HashMap具有同步的能力，或者使用ConcurrentHashMap。
- Hashtable与 HashMap类似，它继承自Dictionary类。不同的是：Hashtable不允许记录的键或者值为空；它支持线程的同步（即任一时刻只有一个线程能写Hashtable），因此也导致了 Hashtable在写入时会比较慢。

**LinkedHashMap**

- **保存插入顺序**：LinkedHashMap保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的。也可以在构造时带参数，按照应用次数排序。
- **速度慢**：在遍历的时候会比HashMap慢，不过有种情况例外：当HashMap容量很大，实际数据较少时，遍历起来可能会比LinkedHashMap慢。因为LinkedHashMap的遍历速度只和实际数据有关，和容量无关，而HashMap的遍历速度和他的容量有关。

##### Q&A 高性能场景下HashMap性能优化？

1. 考虑初始化大小
2. 减小负载因子
3. String类型的key,不能用==判断，
4. 使用定制版的EnumMap
5. 使用IntObjectHashMap

#####  Q&A  HashMap 与 HashSet 区别?

HashSet和HashMap之间有很多相似之处。对于HashSet而言，系统采用Hash算法决定集合元素的存储位置，这样可以保证快速存、取集合元素；对于HashMap而言，系统将value当成key的附属，系统根据Hash算法来决定key的存储位置，这样可以保证快速存、取集合key，而value总是紧随key存储。

HashSet的add()方法添加集合元素时实际上转变为调用HashMap的put()方法来添加 key-value对，当新放入 HashMap的Entry 中key 与集合中原有Entry的key 相同（hashCode()返回值相等，通过equals比较也返回true）时，新添加的Entry的value将覆盖原来Entry的value，但key不会有任何改变。因此，如果向HashSet中添加一个已经存在的元素，新添加的集合元素（底层由HashMap的key保存）不会覆盖已有的集合元素

##### Q&A ArrayList和Vector有何异同点？

相同点：

1. 两者都是基于索引的，都是基于数组的。
2. 两者都维护插入顺序，我们可以根据插入顺序来获取元素。
3. ArrayList 和 Vector 的迭代器实现都是 fail-fast 的。
4. ArrayList 和 Vector 两者允许 null 值，也可以使用索引值对元素进行随机访问。

不同点：

1. Vector 是同步，线程安全，而 ArrayList 非同步，线程不安全。对于 ArrayList，如果 迭代时改变列表，应该使用 CopyOnWriteArrayList。
2. 但是，ArrayList 比 Vector 要快，它因为有同步，不会过载。
3. 在使用上，ArrayList 更加通用，因为 Collections 工具类容易获取同步列表和只读列 表。ArrayList在并发add()可能出现下标越界异常。

#####  Q&A ArrayList 与 LinkedList 区别 ?

ArrayList 和 LinkedList 都实现了 List 接口，他们有以下的不同点： ArrayList 是基于索引的数据接口，它的底层是数组。它可以以 O(1)时间复杂度对元素进行 随机访问。与此对应，LinkedList 是以元素列表的形式存储它的数据，每一个元素都和它的 前一个和后一个元素链接在一起，在这种情况下，查找某个元素的时间复杂度是 O(n)。 相对于 ArrayList，LinkedList 的插入，添加，删除操作速度更快，因为当元素被添加到集合 任意位置的时候，不需要像数组那样重新计算大小或者是更新索引。 LinkedList 比 ArrayList 更占内存，因为 LinkedList 为每一个节点存储了两个引用，一个指 向前一个元素，一个指向下一个元素。 

##### Q&A  数组(Array)和列表(ArrayList)有什么区别？什么时候应该使用 Array 而不是 ArrayList？

array包含基本类型和对象类型。Arraylist只能包含对象类型。

Arraylist是采用数组实现的，arraylist是可以自动扩容的。比array提供了更多的特性，比如 addAll(),removeAll() 等。

##### Q&A 使用ArrayList的迭代器会出现什么问题？单线程和多线程环境下； 

常用的迭代器设计模式，iterator 方法返回一个父类实现的迭代器。 1、迭代器的 hasNext 方法的作用是判断当前位置是否是数组最后一个位置，相等为 false， 否则为 true。 2、迭代器 next 方法用于返回当前的元素，并把指针指向下一个元素，值得注意的是，每次 使用 next 方法的时候，都会判断创建迭代器获取的这个容器的计数器 modCount 是否与此 时 的 不 相 等 ， 不 相 等 说 明 集 合 的 大 小 被 修 改 过 ， 如 果 是 会 抛 出 ConcurrentModificationException 异常，如果相等调用 get 方法返回元素即可

##### Q&A ArrayList中的源码中的数组的扩容使用的Arrays.copyof()的理解，以及System.arraycopy()

Arrays.copyOf()复制指定的数组，用空值截断或填充（如有必要），使副本具有指定的长度。 对于在原始数组和副本中都有效的所有索引，这两个数组将包含相同的值。 对于副本中有效但不是原始索引的任何索引，副本将包含null 。 当且仅当指定的长度大于原始数组的长度时，此类索引才会存在。 结果数组属于newType类.

实际是调用了System.arraycopy()方法

<font color="red">System中提供了一个native静态方法arraycopy(),可以使用这个方法来实现数组之间的复制。对于一维数组来说，这种复制属性值传递，修改副本不会影响原来的值。对于二维或者一维数组中存放的是对象时，复制结果是一维的引用变量传递给副本的一维数组，修改副本时，会影响原来的数组。</font>

```java
public static native void arraycopy(Object src,  int  srcPos,
                                        Object dest, int destPos,
                                        int length);
```

从指定的源数组中复制一个数组，从指定位置开始，到目标数组的指定位置。 数组组件的子序列从src引用的源数组复制到dest引用的目标数组。 复制的组件数等于length参数。 源数组中位置srcPos到srcPos+length-1处的组件分别复制到目标数组的位置destPos到destPos+length-1 。
如果src和dest参数引用同一个数组对象，则执行复制就像将srcPos到srcPos+length-1位置的分量首先复制到具有length分量的临时数组，然后将临时数组的内容复制到通过目标数组的destPos+length-1复制到位置destPos

##### Q&A  List和Set的区别

list和set都是Collection接口的实现。List接口的实现包括ArrayList和LinkedList。Set接口的实现包括HashSet和TreeSet.

list可以允许重复对象，set不允许重复对象。

list可以插入多个null元素，而set只允许插入一个null元素

list是一个有序的容器，保持每个元素的插入顺序，而set是无序容器，无法保证每个元素的存储顺序，TreeSet通过Comparator或者Comparable维护了一个排序顺序。

#### 泛型的面试题

##### Q&A  Java中的泛型是什么 ? 使用泛型的好处是什么?

在集合中存储对象并在使用前进行类型转换是多么的不方便。泛型防止了那种情况的发生。它提供了编译期的类型安全，确保你只能把正确类型的对象放入 集合中，避免了在运行时出现ClassCastException

##### Q&A Java的泛型是如何工作的 ? 什么是类型擦除 ?

泛型是通过类型擦除来实现的，编译器在编译时擦除了所有类型相关的信息，所以在运行时不存在任何类型相关的信息。例如 `List<String>`在运行时仅用一个List来表示。这样做的目的，是确保能和Java 5之前的版本开发二进制类库进行兼容。你无法在运行时访问到类型参数，因为编译器已经把泛型类型转换成了原始类型。

##### Q&A  什么是泛型中的限定通配符和非限定通配符 ?

限定通配符对类型进行了限制。有两种限定通配符，一种是`<? extends T>`它通过确保类型必须是T的子类来设定类型的上界，另一种是`<? super T>`它通过确保类型必须是T的父类来设定类型的下界。泛型类型必须用限定内的类型来进行初始化，否则会导致编译错误。另一方面`<?>`表 示了非限定通配符，因为`<?>`可以用任意类型来替代

##### Q&A List<? extends T> 上界 和List <? super T> 下界 之间有什么区别 ?

上界的list只能get不能add,下届的list只能add不能get

编译器可以支持像上转型，不支持像下转型。

##### Q&A 你可以把`List<String>`传递给一个接受`List<Object>`参数的方法吗？

因为`List<Object>`可以存储任何类型的对象包括String, Integer等等，而`List<String>`却只能用来存储Strings。

`List<Object> objectList`;

`List<String> stringList;`

objectList = stringList; //compilation error incompatible types

```java
public static void main(String[] args) {
        List<String> stringList = new ArrayList<>();
        List<Object> objectList = new ArrayList<>();
        stringList.add("add");
        stringList.add("123");
        objectList.add("123");
        objectList.add("234");
        // 让objectList转为stringList,编译错误stringList必须是接收的List<String> List<Object>之间不能转换。
        // stringList= objectList; // 编译错误
        // objectList=stringList; // 编译错误
        List<?> list = new ArrayList<>();
        list = stringList;
        System.out.println(list);
        list = objectList;
        System.out.println(list);
        // list.add("sss"); // 编译器不允许这样使用
        
    }
```

#### 异常常见的面试题：

##### Q&A java中用来抛出异常的关键字是什么？

throw

##### Q&A 异常和Error（错误）的区别？ 

error：是不可捕捉到的，无法采取任何恢复的操作，顶多只能显示错误信息。
Exception ：表示可恢复的例外，这是可捕捉到的

##### Q&A 什么是异常？

所谓异常是指程序在运行过程中发生的一些不正常事件。（如：除0溢出，数组下标越界，所读取的文件不存在）

##### Q&A 什么类是所有异常类的父类 

Throwable类

##### Q&Ajava  虚拟机能自动处理的异常是什么？

运行异常

##### Q&A  Try-catch-finally的执行过程 

1. try{}语句块中放的是要检测的java代码，可能有会抛出异常，也可能会正常执行
2. catch（异常类型）{}块是当java运行时系统接收到try块中所抛出异常对象时，会寻找处理这一异常catch块来进行处理（可以有多个catch块）
3. finally{}不管系统有没有抛出异常都会去执行，一般用来释放资源。除了在之前执行了System.exit（0）

##### Q&A 常见的异常？你的理解。

常见异常：RuntimeException,IOException,SQLException,ClassNotFoundException

##### Q&A final, finally, finalize的区别。

1. final用于声明属性，方法和类，分别表示属性不可交变，方法不可覆盖，类不可继承。
2. finally是异常处理语句结构的一部分，表示总是执行。
3. finalize是Object类的一个方法，在垃圾收集器执行的时候会调用被回收对象的此方法，供垃圾收集时的其他资源回收，例如关闭文件等。（**在垃圾回收的时候会调用被回收对象的此方法。**）

##### Q&AJava 中的异常处理机制的简单原理和应用。

​     当JAVA程序违反了JAVA的语义规则时，JAVA虚拟机就会将发生的错误表示为一个异常。违反语义规则包括2种情况。一种是JAVA类库内置的语义检查。例如数组下标越界,会引发IndexOutOfBoundsException;访问null的对象时会引发NullPointerException。另一种情况就是JAVA允许程序员扩展这种语义检查，程序员可以创建自己的异常，并自由选择在何时用throw关键字引发异常。所有的异常都是java.lang.Thowable的子类。

##### Q&A 运行时异常与一般异常有何异同？

Java提供了两类主要的异常:运行时异常runtime exception和一般异常checked exception。checked 异常。对于后者这种异常，JAVA要求程序员对其进行catch。所以，面对这种异常不管我们是否愿意，只能自己去写一大堆catch块去处理可能的异常。

运行时异常我们可以不处理。这样的异常由虚拟机接管。出现运行时异常后，系统会把异常一直往上层抛，一直遇到处理代码。如果不对运行时异常进行处理，那么出现运行时异常之后，要么是线程中止，要么是主程序终止。

##### Q&A 你平时在项目中是怎样对异常进行处理的。 

1. 尽量避免出现runtimeException 。例如对于可能出现空指针的代码，带使用对象之前一定要判断一下该对象是否为空，必要的时候对runtimeException也进行try catch处理。
2. 进行try catch处理的时候要在catch代码块中对异常信息进行记录，通过调用异常类的相关方法获取到异常的相关信息，返回到web端，不仅要给用户良好的用户体验，也要能帮助程序员良好的定位异常出现的位置及原因。

#### 线程的面试题：

##### Q&A 什么是线程？

 线程是程序执行运算的最小的基本单位

##### Q&A线程与进程的区别？

- 进程是系统中正在运行的一个应用程序，表示资源分配的基本单位。又是调度运行的基本单位。
- 一个线程只能属于一个进程，而一个进程可以拥有多个线程。
- 同一进程的所有线程共享该进程的所有资源。同一进程的多个线程共享代码段。

##### Q&A 如何保证线程安全？

加锁是最简单的直接的方式。synchronized关键字

##### Q&A 如何使用线程？线程是如何启动的？

- 实现runnable接口，

- 实现Callable接口，

- 继承Thread类，
- 线程启动，重写run方法然后调用start()即可开启一个线程。

##### Q&A 线程的几种状态？

5种状态：创建，就绪，运行状态，阻塞，死亡

线程创建时new状态，调用start()进入runnable就绪状态，争夺cpu资源后进入running状态，由于某种原因进入

1. 等待阻塞：运行的线程会释放占用的所有资源，jvm会把该线程放入“等待池”进入这个状态后，是不能自动唤醒的，必须依靠其他线程调用notify()或notifyAll()方法才能被唤醒，
2. 同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入“锁池”中。
3. 其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。
   当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。
   当线程正常执行结束会进入dead状态（一个未捕获的异常也会使线程终止）

- yield()只是使当前线程重新回到runnable状态
- sleep()会让出cpu，不会释放锁
- join()会让出cpu，释放锁
- wait() 和 notify() 方法与suspend()和 resume()的区别在于wait会释放锁，suspend不会释放锁
- wait() 和 notify()只能运行在Synchronized代码块中，因为wait()需要释放锁，如果不在同步代码块中，就无锁可以释放
- 当线程调用wait()方法后会进入等待队列（进入这个状态会释放所占有的所有资源，与阻塞状态不同），进入这个状态后，是不能自动唤醒的，必须依靠其他线程调用notify()或notifyAll()方法才能被唤醒

##### Q&A 并发和并行的区别？

并发：同一时段，多个任务都在执行，

并行：单位时间内多个任务同时执行。

##### Q&A 使用多线程带来什么问题可能？

并发是为了能提高程序的执行效率提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、上下文切换、死锁

##### Q&A 什么是死锁？如何避免死锁？

死锁:死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程

**破坏死锁的四个条件：**

1. 互斥条件：该资源任意一个时刻只由一个线程占用。 （无法破坏）
2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。（可以使用一次性申请所有资源）
3. 不剥夺条件:线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。（占用部分资源线程去申请其他资源，如果不能申请到就主动释放它占有的资源）
4. 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。（按顺序申请资源。）

##### Q&A **sleep（）和wait()方法的区别？**

- sleep方法会让出cpu没有释放锁，wait方法释放了锁。

- 两者都可以暂停线程的执行。
- Wait 通常被用于线程间交互/通信，sleep 通常被用于暂停执行。
- wait() 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 notify() 或者 notifyAll() 方法。sleep() 方法执行完成后，线程会自动苏醒。或者可以使用wait(long timeout)超时后线程会自动苏醒。

##### Q&A  介绍一下Syncronized锁，

synchronized修饰静态方法以及同步代码块的Synchronized用法锁的是类，线程想要执行对应的同步代码就需要或的类锁。synchronized修饰成员方法，线程获取的是调用当前对象实例的对象锁。

##### Q&A Synchonized关键字用在静态方法中和非静态方法有什么区别

Synchronized在静态方法中是加在的类级别的锁称为“类锁”，而在非静态方法中的使用的是加入的方法级别的锁称为‘’对象锁‘’。

对于对象锁：同一个对象在两个线程中分别访问该对象的两个同步方法会产生互斥，因为是对象锁，所以当对象调用一个synchronized方法时，其他同步方法需要等待其执行结束并释放锁后才能执行。不同对象在两个线程中调用同一个同步方法，不会产生互斥。

对于类锁：用类直接在两个线程中调用两个不同的同步方法时会产生互斥，因为类对象只有一个。用一个类的静态对象在两个线程中调用静态方法或非静态方法，会产生互斥，因为时一个对象调用。一个对象在两个线程中分别调用一个静态同步方法和一个非静态同步方法，不会产生互斥，因为两个方法的锁类型不一致，因此不会互斥，会进行并发执行。

##### Q&A 介绍一下syncronized的锁的升级过程

无锁->偏向锁(jdk15取消了)->轻量锁->重量锁

##### Q&A  介绍一下Synchronized和lock，

synchronized是java的关键字，当用来修饰一个方法或者代码块的时候，能够保证在同一时刻最多只有一个线程执行该代码。jdk1.5后引入自旋锁，锁粗化，轻量级锁，偏向锁来优化关键字的性能。

Lock是一个接口，Synchronized发生异常时自动释放线程占有的锁，因此不会导致死锁的现象。Lock发生异常时需要通过unLock()去释放锁，则需要在使用finally块中释放锁，Lock可以让等待锁的线程响应中断，而synchronized却不行，synchronized时等待的线程会一直等待。Lock可以知道是否成功获取锁，而synchronized却无法办到。

##### Q&A  介绍一下volatile

1. volatile修饰的是保障有序性和可见性，比如我们写的代码不一定会按照我们书写的顺序来执行。
2. volatile是Java提供的轻量级的同步机制，比sync的开销要小
3. 被volatile定义的变量,系统每次用到它时都是直接从主存中读取,而不是各个线程的工作内存
4. volatile可以像sync一样保持变量在多线程环境中是实时可见的

可见性：

每个线程都有自己的工作内存，每次线程执行时，会从主存获得变量的拷贝，对变量的操作是在线程的工作内存中进行，不同的线程之间不共享工作内存；对于volatile（sync，final）来说，打破了上述的规则，当线程修改了变量的值，其他线程可以立即知道该变量的改变。而对于普通变量，当一个线程修改了变量，需要将变量写回主存，其他线程从主存中读取变量后才对该线程可见

volatile具有sync的可见性，但是不具备原子性（解决java多线程的执行有序性）。volatile适用于多个变量之间或者某个变量当前值和修改之后值之间没有约束。因此，单独使用volatile还不足以实现计数器，互斥锁等。

在并发编程中谈及到的无非是可见性、有序性及原子性。而这里的Volatile只能够保证前两个性质，对于原子性还是不能保证的，只能通过锁的形式帮助他去解决原子性操作

```java
public class Test {
    private volatile  int inc=0;

    public  void  increase(){
        inc++;
    }
    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i<10;i++){
            new Thread(() -> {
                for (int j=0;j<1000;j++){
                    test.increase();
                }
            }).start();
        }
        while(Thread.activeCount()>1){
            Thread.yield();
        }
        System.out.println(test.inc);
    }
}
// ~OUTPUT 这个输出的数字是小于10000的
```



##### Q&A ThreadLocal的如何避免内存泄露

##### Q&A Java中的CAS unsafe方法  CAS的缺陷

##### Q&A Synchronized为何能保证线程安全

Synchronized的语义底层是通过一个monitor的对象来完成，其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。

1、monitorenter：
每个对象有一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：

1.如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。
2.如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1.
3.如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。
2、monitorexit：
执行monitorexit的线程必须是objectref所对应的monitor的所有者。

指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个 monitor 的所有权。

### Spring全家桶

#### Spring 

##### Q&A 什么是spring

Spring是提供一种方法的管理的业务对象，Spring是全面的模块的，Spring是潜在地一站式解决方案，定位于与典型应用相关的大部分基础结构。它也涉及到其他framework没有考虑到的内容。可以降低开发企业应用的复杂程度，以IoC(控制反转)和AOP(面向切面编程)两种技术为基础简化了企业开发的复杂性，方便解耦，简化开发 Spring 就是一个大工厂，可以将所有对象创建和依赖关系维护，交给 Spring 管理 AOP 编程的支持 Spring 提供面向切面编程，可以方便的实现对程序进行权限拦截、运行监控等功能 声明式事务的支持 只需要通过配置就可以完成对事务的管理，而无需手动编程 方便程序的测试 Spring 对 Junit4 支持，可以通过注解方便的测试 Spring 程序 方便集成各种优秀框架

##### Q&A Spring包含哪些模块

`核心模块：` spring core是核心容器实现了IoC模式，提供了框架的基础功能，在模块中包含BeanFactory类，负责对JavaBean配置与管理采用Factory模式实现loC容器即依赖注入。

`Context模块：` 继承了BeanFactory并且添加了处理事件，国际化,资源装载，数据校验等，JNDI访问，ejb,远程调用，集成模块框架，Email,定时任务。

`AOP模块`：通过事务管理使得任意Spring管理的对象AOP化。

`DAO模块`：JDBC的抽象层，简化数据库的厂商的异常错误，减少了代码的书写，并且提供了声明式的任务，和编程式任务。

`O/R映射模块`：直接用Hibernate。

`Web模块`：建立在Spring Context 模块的基础，提供servlet监听器的Context和web应用上下文

`mvc模块`：建立在Spring 核心功能之上，使得拥有Spring框架的所有特性适应于多种的视图模块技术

##### Q&A 使用spring框架能带来哪些好处

大大节约开发成本，很多组件开箱即用。

##### Q&A Spring有几种配置方式

xml配置，java配置，注解配置。

##### Q&A IOC是什么

IoC 即控制反转，简单来说就是把原来代码⾥需要实现的对象创建、初始化，销毁，依赖反转给容器来帮忙实现，不需要开发者进行控制，实现控制反转。需要创建⼀个容器并且需要⼀种描述让容器知道要创建的对象间的关系，在 Spring 中管理对象及其依赖关系是通过 Spring 的 IoC 容器实现的。 

IoC 的实现⽅式有依赖注⼊和依赖查找，由于依赖查找使⽤的很少，因此 IoC 也叫做依赖注⼊。依赖注 ⼊指对象被动地接受依赖类⽽不⽤⾃⼰主动去找，对象不是从容器中查找它依赖的类，⽽是在容器实例 化对象时主动将它依赖的类注⼊给它。假设⼀个 Car 类需要⼀个 Engine 的对象，那么⼀般需要需要⼿ 动 new ⼀个 Engine，利⽤ IoC 就只需要定义⼀个私有的 Engine 类型的成员变量，容器会在运⾏时⾃ 动创建⼀个 Engine 的实例对象并将引⽤⾃动注⼊给成员变量。

##### Q&A IOC容器初始化过程

IoC容器的初始化包括**BeanDefinition的Resouce定位**、**载入**和**注册**这三个基本的过程

**BeanDefinition**描述和定义了创建一个Bean需要的所有信息，属性，构造函数参数以及访问它们的方法。还有其他一些信息，比如这些定义来源自哪个类等等信息

**Resouce定位：** BeanDefinition的资源定位由ResourceLoader通过统一的Resource接口来完成，这个Resource对各种形式的BeanDefinition的使用提供了统一接口。比如说，在文件系统中的Bean定义信息可以使用FileSystemResource来进行抽象；在类路径中可以使用前面提到的ClassPathResource来使用，等等。这个过程类似于容器寻找数据的过程，就像用水桶装水先要把水找到一样

**BeanDefinition的载入：**第二个关键的部分是BeanDefinition的载入，该载入过程把用户定义好的Bean表示成IoC容器内部的数据结构，而这个容器内部的数据结构就是BeanDefinition，总地说来，这个BeanDefinition定义了一系列的数据来使得IoC容器能够方便地对POJO对象也就是Spring的Bean进行管理。即BeanDefinition就是Spring的领域对象模型

**BeanDefinition的注册：**第三个过程是向IoC容器注册这些BeanDefinition的过程。这个过程是通过调用BeanDefinitionRegistry接口的实现来完成的，这个注册过程把载入过程中解析得到的BeanDefinition向IoC容器进行注册。可以看到，在IoC容器内部，是通过使用一个HashMap来持有这些BeanDefinition数据的。

**基于** **XML** **的容器初始化** 

当创建⼀个 ClassPathXmlApplicationContext 时，构造⽅法做了两件事：① 调⽤⽗容器的构造⽅法为 容器设置好 Bean 资源加载器。② 调⽤⽗类的 setConfigLocations ⽅法设置 Bean 配置信息的定位 路径。 

ClassPathXmlApplicationContext 通过调⽤⽗类 AbstractApplicationContext 的 refresh ⽅法启动 整个 IoC 容器对 Bean 定义的载⼊过程， refresh 是⼀个模板⽅法，规定了 IoC 容器的启动流程。在 创建 IoC 容器前如果已有容器存在，需要把已有的容器销毁，保证在 refresh ⽅法后使⽤的是新创建 的 IoC 容器。 

容器创建后通过 loadBeanDefinitions ⽅法加载 Bean 配置资源，该⽅法做两件事：① 调⽤资源加 载器的⽅法获取要加载的资源。② 真正执⾏加载功能，由⼦类 XmlBeanDefifinitionReader 实现。加载 资源时⾸先解析配置⽂件路径，读取配置⽂件的内容，然后通过 XML 解析器将 Bean 配置信息转换成 ⽂档对象，之后按照 Spring Bean 的定义规则对⽂档对象进⾏解析。

Spring IoC 容器中注册解析的 Bean 信息存放在⼀个 HashMap 集合中，key 是字符串，值是 BeanDefifinition，注册过程中需要使⽤ synchronized 保证线程安全。当配置信息中配置的 Bean 被解 析且被注册到 IoC 容器中后，初始化就算真正完成了，Bean 定义信息已经可以使⽤且可被检索。 Spring IoC 容器的作⽤就是对这些注册的 Bean 定义信息进⾏处理和维护，注册的 Bean 定义信息是控 制反转和依赖注⼊的基础。

**基于注解的容器初始化** 

分为两种：① 直接将注解 Bean 注册到容器中，可以在初始化容器时注册，也可以在容器创建之后⼿动 注册，然后刷新容器使其对注册的注解 Bean 进⾏处理。② 通过扫描指定的包及其⼦包的所有类处理， 在初始化注解容器时指定要⾃动扫描的路径。

##### Q&A 依赖注入的方式，以及各个之间的区别

构造方法注入：参数变动需要更改构造函数，维护变动困难。

setter方法注入：只需要对属性进行添加setter方法，允许设置默认值，可以被继承。

接口注入：必须实现某个接口，接口提供的方法为其注入依赖对象，使用少，入侵性强。

##### Q&A 依赖注入的过程

getBean ⽅法获取 Bean 实例，该⽅调⽤ doGetBean ， doGetBean 真正实现从 IoC 容器获取 Bean 的功能，也是触发依赖注⼊的地⽅。 

具体创建 Bean 对象的过程由 ObjectFactory 的 createBean 完成，该⽅法主要通过 createBeanInstance ⽅法⽣成 Bean 包含的 Java 对象实例和 populateBean ⽅法对 Bean 属性的 依赖注⼊进⾏处理。

在 populateBean ⽅法中，注⼊过程主要分为两种情况：① 属性值类型不需要强制转换时，不需要解 析属性值，直接进⾏依赖注⼊。② 属性值类型需要强制转换时，⾸先解析属性值，然后对解析后的属性 值进⾏依赖注⼊。依赖注⼊的过程就是将 Bean 对象实例设置到它所依赖的 Bean 对象属性上，真正的 依赖注⼊是通过 setPropertyValues ⽅法实现的，该⽅法使⽤了委派模式。 

BeanWrapperImpl 类负责对完成初始化的 Bean 对象进⾏依赖注⼊，对于⾮集合类型属性，使⽤ JDK 反射，通过属性的 setter ⽅法为属性设置注⼊后的值。对于集合类型的属性，将属性值解析为⽬标类型 的集合后直接赋值给属性。 

当容器对 Bean 的定位、载⼊、解析和依赖注⼊全部完成后就不再需要⼿动创建对象，IoC 容器会⾃动 为我们创建对象并且注⼊依赖。

##### Q&A 谈你经常用的Spring依赖注入的注解

@Autowired ：⾃动按类型注⼊，如果有多个匹配则按照指定 Bean 的 id 查找，查找不到会报错。 

@Qualifier ：在⾃动按照类型注⼊的基础上再按照 Bean 的 id 注⼊，给变量注⼊时必须搭配 

@Autowired ，给⽅法注⼊时可单独使⽤。 

@Resource ：直接按照 Bean 的 id 注⼊，只能注⼊ Bean 类型。 

@Value ：⽤于注⼊基本数据类型和 String 类型。

##### Q&A Spring 是如何注入集合的

使用标`<list>``<set>``<map>,<props>` ...

##### Q&A Spring 是如何注入java properties的

使用`<props>`标签

##### Q&A Spring中注入null和空串可以吗

可以在`<property>`标签中给使用`<null/>`标签即可注入null值。空串就是可以在property的value属性进行赋值为空串

##### Q&A Bean的生命周期

在 IoC 容器的初始化过程中会对 Bean 定义完成资源定位，加载读取配置并解析，最后将解析的 Bean 信息放在⼀个 HashMap 集合中。当 IoC 容器初始化完成后，会进⾏对 Bean 实例的创建和依赖注⼊过 程，注⼊对象依赖的各种属性值，在初始化时可以指定⾃定义的初始化⽅法。经过这⼀系列初始化操作 后 Bean 达到可⽤状态，接下来就可以使⽤ Bean 了，当使⽤完成后会调⽤ destroy ⽅法进⾏销毁，此 时也可以指定⾃定义的销毁⽅法，最终 Bean 被销毁且从容器中移除。 

XML ⽅式通过配置 bean 标签中的 init-Method 和 destory-Method 指定⾃定义初始化和销毁⽅法。 

注解⽅式通过 @PreConstruct 和 @PostConstruct 注解指定⾃定义初始化和销毁⽅法。

##### Q&A Bean的创建过程（源码层面了）



##### Q&A Bean的作用域的理解

通过 scope 属性指定 bean 的作⽤范围，包括： 

① singleton：单例模式，是默认作⽤域，不管收到多少 Bean 请求每个容器中只有⼀个唯⼀的 Bean 实 例。 

② prototype：原型模式，和 singleton 相反，每次 Bean 请求都会创建⼀个新的实例。 

③ request：每次 HTTP 请求都会创建⼀个新的 Bean 并把它放到 request 域中，在请求完成后 Bean 会失效并被垃圾收集器回收。 

④ session：和 request 类似，确保每个 session 中有⼀个 Bean 实例，session 过期后 bean 会随之失 效。 

⑤ global session：当应⽤部署在 Portlet 容器时，如果想让所有 Portlet 共⽤全局存储变量，那么该变 量需要存储在 global session 中。

##### Q&A inner Beans 的理解

在 Spring 框架中，无论何时 bean 被使用时，当仅被调用了一个属性。一个明智的做法是将这个 bean 声明为内部 bean。内部 bean 可以用 setter 注入“属性”和构造方法注入“构造参数”的方式来实现。 

##### Q&A Spring中的单例bean是线程安全的吗

Spring 框架并没有对单例 bean 进行任何多线程的封装处理。关于单例 bean 的线程安全和并发问 题需要开发者自行去搞定。但实际上，大部分的 Spring bean 并没有可变的状态(比如 Serview 类 和 DAO 类)，所以在某种程度上说 Spring 的单例 bean 是线程安全的。如果你的 bean 有多种状 态的话（比如 View Model 对象），就需要自行保证线程安全。 

最浅显的解决办法就是将多态 bean 的作用域由“singleton”变更为“prototype”。

##### Q&A Spring bean的自动装配的理解

在 Spring 框架中，在配置文件中设定 bean 的依赖关系是一个很好的机制，Spring 容器还可以自 动装配合作关系 bean 之间的关联关系。这意味着 Spring 可以通过向 Bean Factory 中注入的方 式自动搞定 bean 之间的依赖关系。自动装配可以设置在每个 bean 上，也可以设定在特定的 bean 上。 一般我们都是用注解进行实现自动装配bean的

##### Q&A Spring 有哪几种自动装配模式

spring有5种自动装配的模式

no: 使用默认的设置，该模式下自动装配是关闭的。

byName:可以根据bean的名称设置依赖关系

byType:通过bean的类型名称设置依赖关系。

constructor:构造器的自动装配和byType模式类似，仅仅适用于与构造其参数相同的bean如果没找到抛出异常

autodetect:自动试探模式，是使用构建按装配或者使用byType模式进行装配

##### Q&A 如何基于注解开启自动装配

spring在2.5版本后可以支持注解的方式进行配置依赖注入，可以使用注解的方式替代XML方式的bean的描述，可以将bean的描述不使用xml配置而是通过注解的方式。使用

`<context:annotation-config/>`进行开启基于注解驱动的自动装配。

##### Q&A @Autowired和@Resource的区别,@Qualifier

@Autowired默认使用的byType进行注入的

@Resource是通过byName注入的。@Resource有两个属性分别是type属性和name属性，如果指定那个属性就可以按照哪种方式注入，默认的是按照byName属性注入的。

@Qualifier 注解意味着可以在被标注 bean 的字段上可以自动装配。Qualifier 注 解可以用来取消 Spring 不能取消的 bean 应用。

##### Q&A @Required注解的理解

在产品级别的应用中，IoC 容器可能声明了数十万了 bean，bean 与 bean 之间有着复杂的依赖关 系。设值注解方法的短板之一就是验证所有的属性是否被注解是一项十分困难的操作。可以通过在 bean标签中设置“dependency-check”来解决这个问题。 

在应用程序的生命周期中，你可能不大愿意花时间在验证所有 bean 的属性是否按照上下文文件正 确配置。或者你宁可验证某个 bean 的特定属性是否被正确的设置。即使是用“dependency-check”属性也不能很好的解决这个问题，在这种情况下，你需要使用@Required 注解。

RequiredAnnotationBeanPostProcessor 是 Spring 中的后置处理用来验证被 @Required 注解的 bean 属性是否被正确的设置了。在使用 RequiredAnnotationBeanPostProcesso 来验证 bean 属性之前，首先要在 IoC 容器中对 其进行注册。

##### Q&A BeanFactory ,FactoryBean，ApplicationContext的区别

BeanFactory 是⼀个 Bean ⼯⼚，使⽤简单⼯⼚模式，是 Spring IoC 容器顶级接⼝，可以理解为含有 Bean 集合的⼯⼚类，作⽤是管理 Bean，包括实例化、定位、配置对象及建⽴这些对象间的依赖。 BeanFactory 实例化后并不会⾃动实例化 Bean，只有当 Bean 被使⽤时才实例化与装配依赖关系，属 于延迟加载，适合多例模式。 

FactoryBean 是⼀个⼯⼚ Bean，使⽤了⼯⼚⽅法模式，作⽤是⽣产其他 Bean 实例，可以通过实现该 接⼝，提供⼀个⼯⼚⽅法来⾃定义实例化 Bean 的逻辑。FactoryBean 接⼝由 BeanFactory 中配置的对 象实现，这些对象本身就是⽤于创建对象的⼯⼚，如果⼀个 Bean 实现了这个接⼝，那么它就是创建对 象的⼯⼚ Bean，⽽不是 Bean 实例本身。

ApplicationConext 是 BeanFactory 的⼦接⼝，扩展了 BeanFactory 的功能，提供了⽀持国际化的⽂本 消息，统⼀的资源⽂件读取⽅式，事件传播以及应⽤层的特别配置等。容器会在初始化时对配置的 Bean 进⾏预实例化，Bean 的依赖注⼊在容器初始化时就已经完成，属于⽴即加载，适合单例模式，⼀ 般推荐使⽤。 

##### Q&A Spring中有哪些不同类型的事件

Spring 提供了以下 5 中标准的事件： 

1. 上下文更新事件（ContextRefreshedEvent）：该事件会在 ApplicationContext 被初始化或者 更新时发布。也可以在调用 ConfigurableApplicationContext 接口中的 refresh()方法时被触 发。 

2. 上下文开始事件（ContextStartedEvent）：当容器调用 ConfigurableApplicationContext 的 Start()方法开始/重新开始容器时触发该事件。 

3. 上下文停止事件（ContextStoppedEvent）：当容器调用 ConfigurableApplicationContext 的 Stop()方法停止容器时触发该事件。 

4. 上下文关闭事件（ContextClosedEvent）：当 ApplicationContext 被关闭时触发该事件。容器 被关闭时，其管理的所有单例 Bean 都被销毁。 

5. 请求处理事件（RequestHandledEvent）：在 Web 应用中，当一个 http 请求（request）结束 触发该事件。 除了上面介绍的事件以外，还可以通过扩展ApplicationEvent 类来开发自定义的事件

##### Q&A FileSystemResource和ClassPathResouce的区别

在 FileSystemResource 中需要给出 spring-config.xml 文件在你项目中的相对路径或者 绝对路径。在 ClassPathResource 中 spring 会在 ClassPath 中自动搜寻配置文件，所以要把 ClassPathResource 文件放在 ClassPath 下。 

如果将 spring-config.xml 保存在了 src 文件夹下的话，只需给出配置文件的名称即可，因为 src 文件夹是默认。 简而言之，ClassPathResource 在环境变量中读取配置文件，FileSystemResource 在配置文件 中读取配置文件

##### Q&A spring中有哪些设计模式

Spring 框架中使用到了大量的设计模式，下面列举了比较有代表性的：  

- 代理模式—在 AOP 和 remoting 中被用的比较多。  
- 单例模式—在 spring 配置文件中定义的 bean 默认为单例模式。
- 模板方法—用来解决代码重复的问题。比如. RestTemplate, JmsTemplate, JpaTempl ate。 
- 前端控制器—Spring 提供了 DispatcherServlet 来对请求进行分发。 
- 视图帮助(View Helper )—Spring 提供了一系列的 JSP 标签，高效宏来辅助将分散的代码 整合在视图里。 
- 依赖注入—贯穿于 BeanFactory / ApplicationContext 接口的核心理念。 
- 工厂模式—BeanFactory 用来创建对象的实例

##### Q&A 什么是AOP

AOP 即⾯向切⾯编程，简单地说就是将代码中重复的部分抽取出来，在需要执⾏的时候使⽤动态代理技术，在不修改源码的基础上对⽅法进⾏增强。 

Spring 根据类是否实现接⼝来判断动态代理⽅式，如果实现接⼝会使⽤ JDK 的动态代理，核⼼是 InvocationHandler 接⼝和 Proxy 类，如果没有实现接⼝会使⽤ CGLib 动态代理，CGLib 是在运⾏时动 态⽣成某个类的⼦类，如果某个类被标记为 fifinal，不能使⽤ CGLib 。 

JDK 动态代理主要通过重组字节码实现，⾸先获得被代理对象的引⽤和所有接⼝，⽣成新的类必须实现 被代理类的所有接⼝，动态⽣成Java 代码后编译新⽣成的 .class ⽂件并重新加载到 JVM 运⾏。JDK 代理直接写 Class 字节码，CGLib 是采⽤ ASM 框架写字节码，⽣成代理类的效率低。但是 CGLib 调⽤ ⽅法的效率⾼，因为 JDK 使⽤反射调⽤⽅法，CGLib 使⽤ FastClass 机制为代理类和被代理类各⽣成⼀个类，这个类会为代理类或被代理类的⽅法⽣成⼀个 index，这个 index 可以作为参数直接定位要调⽤ 的⽅法。 

常⽤场景包括权限认证、⾃动缓存、错误处理、⽇志、调试和事务等

##### Q&A AOP的应用场景

日志记录

缓存

权限认证

##### Q&A Spring AOP和 AspectJAOP的区别

##### Q&A Spring AOP中的代理

AOP中的代理分为静态代理（AspectJ）和动态代理(Spring AOP)，通常使用AspectJ的编译是静态代理的增强，所谓的静态代理就是AOP框架会在编译阶段生成的AOP的代理，也称为编译时增强。

SpringAOP的动态代理主要有两种方式：JDK动态代理和cglib动态代理，JDK动态代理通过反射来接收被代理的类。并且要求被代理的类必须实现一个接口。JDK动态代理的核心是InvocationHandler接口和Proxy类。

##### Q&A AOP的相关注解有哪些

@Aspect ：声明被注解的类是⼀个切⾯ Bean。 

@Before ：前置通知，指在某个连接点之前执⾏的通知。 

@After ：后置通知，指某个连接点退出时执⾏的通知（不论正常返回还是异常退出）。 

@AfterReturning ：返回后通知，指某连接点正常完成之后执⾏的通知，返回值使⽤returning属性接 收。 

@AfterThrowing ：异常通知，指⽅法抛出异常导致退出时执⾏的通知，和 @AfterReturning 只会有 ⼀个执⾏，异常使⽤throwing属性接收

##### Q&A AOP的相关术语有什么

Aspect ：切⾯，⼀个关注点的模块化，这个关注点可能会横切多个对象。 

Joinpoint ：连接点，程序执⾏过程中的某⼀⾏为，即业务层中的所有⽅法。。 

Advice ：通知，指切⾯对于某个连接点所产⽣的动作，包括前置通知、后置通知、返回后通知、异常 

通知和环绕通知。 

Pointcut ：切⼊点，指被拦截的连接点，切⼊点⼀定是连接点，但连接点不⼀定是切⼊点。 

Proxy ：代理，Spring AOP 中有 JDK 动态代理和 CGLib 代理，⽬标对象实现了接⼝时采⽤ JDK 动态代 理，反之采⽤ CGLib 代理。 

Target ：代理的⽬标对象，指⼀个或多个切⾯所通知的对象。 

Weaving ：织⼊，指把增强应⽤到⽬标对象来创建代理对象的

##### Q&A AOP的实现原理

Aop指的是面向切面编程，AOP的关键在于AOP的代理，AOP代理分为静态代理和动态代理，通常使用AspectJ进行代理正强，静态代理就是AOP框架会在编译阶段进行编译增强。

##### Q&A Spring支持的事务管理器都有哪些

##### Q&A Spring的事务管理器你更倾向于哪些

##### Q&A Spring的事务的隔离级别

TransactionDefinition接口中定义五个隔离级别：

`ISOLATION_DEFAULT `这是一个PlatfromTransactionManager默认的隔离级别，使用数据库默认的事务隔离级别.另外四个与JDBC的隔离级别相对应；

`ISOLATION_READ_UNCOMMITTED `这是事务最低的隔离级别，它充许别外一个事务可以看到这个事务未提交的数据。这种隔离级别**会产生脏读，不可重复读和幻像读。**

`ISOLATION_READ_COMMITTED` 保证一个事务修改的数据提交后才能被另外一个事务读取。另外一个事务不能读取该事务未提交的数据。这种事务隔离级别**可以避免脏读出现，但是可能会出现不可重复读和幻像读。**

`ISOLATION_REPEATABLE_READ` 这种事务隔离级别**可以防止脏读，不可重复读。但是可能出现幻像读。**它除了保证一个事务不能读取另一个事务未提交的数据外，还保证了避免下面的情况产生(不可重复读)。

`ISOLATION_SERIALIZABLE` 这是花费最高代价但是最可靠的事务隔离级别。事务被处理为顺序执行。**除了防止脏读，不可重复读外，还避免了幻像读。**

Spring具体的事务管理由PlatformTransactionManager的不同实现类来完成，在Spring容器中配置PlatformTransactionManager Bean时，必须针对不同的环境来配置不同的实现类。

在dao上加入transaction注解，在xml定义声明式事务管理器

```xml
<!-- 定义事务管理器（声明式的事务） --> 
    <bean id="transactionManager"
        class="org.springframework.orm.hibernate3.HibernateTransactionManager">
        <property name="sessionFactory" ref="sessionFactory" />
    </bean>
```

##### Q&A Spring的事务传播行为

事务的7种传播级别：

1） PROPAGATION_REQUIRED ，默认的spring事务传播级别，使用该级别的特点是，如果上下文中已经存在事务，那么就加入到事务中执行，如果当前上下文中不存在事务，则新建事务执行。所以这个级别通常能满足处理大多数的业务场景。

2）PROPAGATION_SUPPORTS ，从字面意思就知道，supports，支持，该传播级别的特点是，如果上下文存在事务，则支持事务加入事务，如果没有事务，则使用非事务的方式执行。所以说，并非所有的包在transactionTemplate.execute中的代码都会有事务支持。这个通常是用来处理那些并非原子性的非核心业务逻辑操作。应用场景较少。

3）PROPAGATION_MANDATORY ， 该级别的事务要求上下文中必须要存在事务，否则就会抛出异常！配置该方式的传播级别是有效的控制上下文调用代码遗漏添加事务控制的保证手段。比如一段代码不能单独被调用执行，但是一旦被调用，就必须有事务包含的情况，就可以使用这个传播级别。

4）PROPAGATION_REQUIRES_NEW ，从字面即可知道，new，每次都要一个新事务，该传播级别的特点是，每次都会新建一个事务，并且同时将上下文中的事务挂起，执行当前新建事务完成以后，上下文事务恢复再执行。

这是一个很有用的传播级别，举一个应用场景：现在有一个发送100个红包的操作，在发送之前，要做一些系统的初始化、验证、数据记录操作，然后发送100封红包，然后再记录发送日志，发送日志要求100%的准确，如果日志不准确，那么整个父事务逻辑需要回滚。
怎么处理整个业务需求呢？就是通过这个PROPAGATION_REQUIRES_NEW 级别的事务传播控制就可以完成。发送红包的子事务不会直接影响到父事务的提交和回滚。

5）PROPAGATION_NOT_SUPPORTED ，这个也可以从字面得知，not supported ，不支持，当前级别的特点就是上下文中存在事务，则挂起事务，执行当前逻辑，结束后恢复上下文的事务。

这个级别有什么好处？可以帮助你将事务极可能的缩小。我们知道一个事务越大，它存在的风险也就越多。所以在处理事务的过程中，要保证尽可能的缩小范围。比如一段代码，是每次逻辑操作都必须调用的，比如循环1000次的某个非核心业务逻辑操作。这样的代码如果包在事务中，势必造成事务太大，导致出现一些难以考虑周全的异常情况。所以这个事务这个级别的传播级别就派上用场了。用当前级别的事务模板抱起来就可以了。

6）PROPAGATION_NEVER ，该事务更严格，上面一个事务传播级别只是不支持而已，有事务就挂起，而PROPAGATION_NEVER传播级别要求上下文中不能存在事务，一旦有事务，就抛出runtime异常，强制停止执行！这个级别上辈子跟事务有仇。

7）PROPAGATION_NESTED ，字面也可知道，nested，嵌套级别事务。该传播级别特征是，如果上下文中存在事务，则嵌套事务执行，如果不存在事务，则新建事务。

##### Q&A Spring的ORM的理解

#### Spring MVC

##### Q&A Spring MVC的组件包涵哪些

##### Q&A Spring MVC的处理过程

##### Q&A @Controller,@RequestMapping，@RestController

##### Q&A Spring MVC的控制器是什么

##### Q&A WebApplicationContext的理解

##### Q&A DispatcherServlet的理解

##### Q&A Spring MVC启动流程



#### Spring Boot

##### Q&A 为什么使用spring boot

##### Q&A spring boot的核心注解

##### Q&A spring boot自动配置的原理

##### Q&A Spring boot的stater,starter-parent

##### Q&A Spring boot的jar包与普通的jar包的区别

##### Q&A Spring boot启动顺序
##### Q&A 什么是Spring Boot

##### Q&A Spring Boot和Spring Cloud的区别

##### Q&A Spring Boot的核心注解

##### Q&A Spring Boot自动配置原理

##### Q&A Spring Boot的特性

##### Q&A Spring Boot的starter了解

##### Q&A Spring Boot 如何处理异常的

##### Q&A Spring Boot 如何使用定时任务

#### Spring Cloud

##### Q&A 微服务的理解

##### Q&A 微服务架构的优势，特点

##### Q&A 微服务于单体 SOA的区别

##### Q&A Spring Cloud中的Rest的理解

##### Q&A 服务注册与发现的组件

##### Q&A 服务注册与发现的原理

##### Q&A Eureka Server的自我保护机制

##### Q&A Eureka Client的理解

##### Q&A Feign的理解

##### Q&A 为何标注@FeignClent就可以进行远程调用

##### Q&A Feign的实现原理

Feign是一个伪客户端，即它不做任何的请求处理。Feign通过处理注解生成request，从而实现简化HTTP API开发的目的，即开发人员可以使用注解的方式定制request api模板，在发送http request请求之前，feign通过处理注解的方式替换掉request模板中的参数，这种实现方式显得更为直接、可理解。

- 启动时，程序会进行包扫描，扫描所有包下所有@FeignClient注解的类，并将这些类注入到spring的IOC容器中。当定义的Feign中的接口被调用时，通过JDK的动态代理来生成RequestTemplate。
- RequestTemplate中包含请求的所有信息，如请求参数，请求URL等。
- RequestTemplate声场Request，然后将Request交给client处理，这个client默认是JDK的HTTPUrlConnection，也可以是OKhttp、Apache的HTTPClient等。
- 最后client封装成LoadBaLanceClient，结合ribbon负载均衡地发起调用。

##### Q&A Hystrix,Hystrix的容错的方式

##### Q&A Eureka和zookeeper的区别

##### Q&A 服务雪崩，服务降级，服务容错

##### Q&A 微服务中的session共享如何实现

### Mybatis

##### Q&A Mybatis的优缺点

##### Q&A Mybatis的缓存，一级缓存，二级缓存

##### Q&A Mybstis的like语句

##### Q&A Mybatis的#{} 和${}区别

##### Q&A mybatis的xml标签有哪些

### Redis

##### Q&A Redis的数据类型

String,List,Set,Sorted Set Hash

##### Q&A Redis的内部的存储的数据类型格式是什么

1.string

string类型对应的是key和value，string类型默认支持三种数据格式：字符串，整数，浮点

在Redis内部，String类型通过 int、SDS(simple dynamic string)作为结构存储，int用来存放整型数据，sds存放字 节/字符串和浮点型数据。Redis是用C语言写的，在C的标准字符串结构下进行了封装，用来提升基本操作的性能，同时也充分利用已有的 C的标准库，简化实现逻辑。

2.list

列表类型内部使用双向链表实现，所以向列表两端添加元素的时间复杂度为O(1), 获取越接近两端的元素速度就越 快。即使是一个有几千万个元素的列表，获取头部或尾部的几条记录也是很快的
不同版本内部数据结构的差异：
redis3.2之前，List类型的value对象内部以linkedlist或者ziplist来实现, 当list的元素个数和单个元素的长度比较小 的时候，Redis会采用ziplist（压缩列表）来实现来减少内存占用。否则就会采用linkedlist（双向链表）结构。
redis3.2之后，采用的一种叫quicklist的数据结构来存储list，列表的底层都由quicklist实现。 这两种存储方式都有优缺点，双向链表在链表两端进行push和pop操作，在插入节点上复杂度比较低，但是内存开 销比较大； ziplist存储在一段连续的内存上，所以存储效率很高，但是插入和删除都需要频繁申请和释放内存；
quicklist仍然是一个双向链表，只是列表的每个节点都是一个ziplist，其实就是linkedlist和ziplist的结合，quicklist 中每个节点ziplist都能够存储多个数据元素，

3.hash

把整体看作一个对象，每个field-value相当于对象的属性和属性值，这个整体的value是个二维表格的形式，可以存储一些对象信息，是个典型的字典结构，在value里面不能在嵌套其他的数据类型的格式。
map提供两种结构来存储，一种是hashtable、另一种是ziplist，数据量小的时候用ziplist. 在redis中，哈 希表分为三层，分别是dictEntry，dictht ，dict ：
dictEntry
管理一个key-value，同时保留同一个桶中相邻元素的指针，用来维护哈希桶的内部链；
dictht
实现一个hash表会使用一个buckets存放dictEntry的地址，一般情况下通过hash(key)%len得到的值就是buckets的 索引，这个值决定了我们要将此dictEntry节点放入buckets的哪个索引里,这个buckets实际上就是我们说的hash 表。dict.h的dictht结构中table存放的就是buckets的地址
dict
dictht实际上就是hash表的核心，但是只有一个dictht还不够，比如rehash、遍历hash等操作，所以redis定义了 一个叫dict的结构以支持字典的各种操作，当dictht需要扩容/缩容时，用来管理dictht的迁移
使用场景：hash的存储方式类似于关系型数据库，可以存储一些对象形式的信息
4.集合类型（set）
集合类型中，每个元素都是不同的，也就是不能有重复数据，同时集合类型中的数据是无序的。一个集合类型键可 以存储至多232-1个 。集合类型和列表类型的最大的区别是有序性和唯一性 集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在。由于集合类型在redis内部是使用的值 为空的散列表(hash table)，所以这些操作的时间复杂度都是O(1).
Set在的底层数据结构以intset或者hashtable来存储。当set中只包含整数型的元素时，采用intset来存储，否则， 采用hashtable存储，但是对于set来说，该hashtable的value值用于为NULL。通过key来存储元素
使用场景：去重，找标签，差集
5，有序集合 sorted-set
有序集合类型，和集合类型的区别就是多了有序的功能
在集合类型的基础上，有序集合类型为集合中的每个元素都关联了一个分数，这使得我们不仅可以完成插入、删除 和判断元素是否存在等集合类型支持的操作，还能获得分数最高(或最低)的前N个元素、获得指定分数范围内的元 素等与分数有关的操作。虽然集合中每个元素都是不同的，但是他们的分数却可以相同 。
zset类型的数据结构就比较复杂一点，内部是以ziplist或者skiplist+hashtable来实现，这里面最核心的一个结构就 是skiplist，也就是跳跃表 。

##### Q&A Redis中的一个字符串的类型的值能存储多大容量。

512M

##### Q&A Redis主要作用

缓存，提升数据检索的速度，存内存操作，

##### Q&A Redis主要适合哪些场景？

（1）会话缓存（Session Cache） 

最常用的一种使用 Redis 的情景是会话缓存（sessioncache），用 Redis 缓存会话比其他存储（如 

Memcached）的优势在于：Redis 提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户 的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？ 幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用 Redis 来缓存会话的文档。甚至广为 人知的商业平台 Magento 也提供 Redis 的插件。 

（2）全页缓存（FPC） 

除基本的会话 token 之外，Redis 还提供很简便的 FPC 平台。回到一致性问题，即使重启了 Redis 实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似 PHP 本地 FPC。 再次以 Magento 为例，Magento 提供一个插件来使用 Redis 作为全页缓存后端。 此外，对 WordPress 的用户来说，Pantheon 有一个非常好的插件 wp-redis，这个插件能帮助你以最快 速度加载你曾浏览过的页面。 

（3）队列 

Reids 在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得 Redis 能作为一个很好的消息队 列平台来使用。Redis 作为队列使用的操作，就类似于本地程序语言（如 Python）对 list 的 push/pop 操作。 如果你快速的在 Google 中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的 就是利用 Redis 创建非常好的后端工具，以满足各种队列需求。例如，Celery 有一个后台就是使用 Redis 作为 broker，你可以从这里去查看。 

（4）排行榜/计数器Redis 在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（SortedSet）也 使得我们在执行这些操作的时候变的非常简单，Redis 只是正好提供了这两种数据结构。 所以，我们要从排序集合中获取到排名最靠前的 10 个用户–我们称之为“user_scores”，我们只需要 像下面一样执行即可： 

当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执 行： 

ZRANGE user_scores 0 10 WITHSCORES 

Agora Games 就是一个很好的例子，用 Ruby 实现的，它的排行榜就是使用 Redis 来存储数据的，你可 以在这里看到。 

（5）发布/订阅 

最后（但肯定不是最不重要的）是 Redis 的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看 见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用 Redis 的发布/订阅功能 来建立聊天系统！

##### Q&A Redis为何是单线程的

因为CPU不是Redis的瓶颈，redis的瓶颈是机器的内存和网络的带宽。所以采用单线程

##### Q&A Redis的哈希槽的概念

Redis 集群没有使用一致性 hash,而是引入了哈希槽的概念，Redis 集群有 16384 个哈希槽，每个 key 通过 CRC16 校验后对 16384 取模来决定放置哪个槽，集群的每个节点负责一部分 hash 槽。 

##### Q&A 缓存雪崩

​	目前电商首页以及热点数据都会去做缓存 ，一般缓存都是定时任务去刷新，或者是查不到之后去更新的，定时任务刷新就有一个问题。

 	当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，会给后端系统带来很大压 力。导致系统崩溃。

**如何避免?**

 1：在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个 key 只允许一个 线程查询数据和写缓存，其他线程等待。

 2：做二级缓存，A1 为原始缓存，A2 为拷贝缓存，A1 失效时，可以访问 A2，A1 缓存失效时间设置 为短期，A2 设置为长期 

 3：不同的 key，设置不同的过期时间，让缓存失效的时间点尽量均匀 

##### Q&A 缓存穿透

 一般的缓存系统，都是按照 key 去缓存查询，如果不存在对应的 value，就应该去后端系统查找（比如  DB）。一些恶意的请求会故意查询不存在的 key,请求量很大，就会对后端系统造成很大的压力。这就叫  做缓存穿透。 

**如何避免?**

 1：对查询结果为空的情况也进行缓存，缓存时间设置短一点，或者该key 对应的数据 insert 了之后清 理缓存。 

 2：对一定不存在的 key 进行过滤。可以把所有的可能存在的 key 放到一个大的 Bitmap 中，查询时通过 该 bitmap 过滤。 

`缓存穿透`我会在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id <=0的直接拦截等。

##### Q&A 缓存击穿

缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力

​      **解决方案：**

1. 设置热点数据永远不过期。<br/>
2. 加互斥锁，互斥锁参考代码如下：

**使用布隆过滤器解决缓存击穿**

`布隆过滤器（Bloom Filter）`这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。

`缓存击穿`的话，设置热点数据永远不过期。或者加上互斥锁就能搞定了

##### Q&A 缓存与数据库双写不一致

一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统不是严格要求 “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：读请求和写请求串行化，串到一个内存队列里去。

串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。

Cache Aside Pattern

最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，先更新数据库，然后再删除缓存。

> **为什么是删除缓存，而不是更新缓存？**

原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。

比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。

**1、最初级的缓存不一致问题以及解决方案**

**问题：**

​	先修改数据库，再删除缓存，如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据出现不一致。

**解决思路：**

　　先删除缓存，再修改数据库，如果删除缓存成功了修改数据库失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致，因为读的时候缓存没有，则读数据库中旧数据，然后更新到缓存中。

　　[![BoYXxH.md.png](https://s1.ax1x.com/2020/11/08/BoYXxH.md.png)](https://imgchr.com/i/BoYXxH)

其实还有以下解决方案：

1. 先删缓存，再更新数据库
2. 先更新数据库，再删缓存
3. 缓存延时双删，更新前先删除缓存，然后更新数据，再延时删除缓存
4. 监听MySQL binlog进行缓存更新

[可参考：缓存与数据库双写一致性最佳解决方案](https://www.jianshu.com/p/dc1e5091a0d8)

**2、并发下数据缓存不一致问题分析**

**问题**：

　　第一个请求数据发生变更，先删除了缓存，然后要去修改数据库，此时还没来得及去修改；

　　第二个请求过来去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中；

　　第三个请求读取缓存中的数据 (此时第一个请求已经完成了数据库修改的操作)。

　　完了，数据库和缓存中的数据不一样了。。。。

**问题分析：**

　　只有在对同一条数据并发读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就1万次，那么很少的情况下，会出现刚才描述的那种不一致的场景;但如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就可能会出现上述的数据库+缓存不一致的情况。

**解决思路**

　　数据库的缓存更新与读取操作进行串行化，一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。

1. 首先我们的项目里维护一组线程池和内存队列。
2. 更新数据的时候，根据数据的唯一标识将请求路由到一个jvm队列中，去更新数据库,然后请求结束。
3. 读取数据的时候，先查缓存，如果发现数据不在缓存中，那么将根据唯一标识路由之后，也发送同一个jvm内部的队列中，重新读取数据库后更新缓存,最后请求结束。

[![BoYLGD.md.png](https://s1.ax1x.com/2020/11/08/BoYLGD.md.png)　　

​		这里有一个需要优化的点，比如一个队列中，连续存在多个更新缓存请求串在一起是没意义的，这样重复的查询数据库并更新缓存的操作应该优化：如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接让后面的读请求阻塞个200ms左右(这里只是举个例子，实际值可以根据服务的响应时间和机器的处理能力来计算)，然后再次查询缓存，如果缓存没有值就查数据库，拿到结果后不用更新缓存，直接返回给页面即可。

[参考：缓存与数据库双写不一致](https://www.cnblogs.com/wlwl/p/11601632.html)

##### Q&A 缓存并发竞争key

其实这个问题就是<font color="red">多个客户端同时并发写一个key可能本来应该先到的数据后到了，导致数据版本错了</font>；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。

而且 redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。

**解决方案**

你要写入缓存的数据，都是从 mysql 里查出来的，都得写入 mysql 中，写入 mysql 中的时候必须保存一个时间戳，从 mysql 查出来的时候，时间戳也查出来。

每次要**写之前，先判断一下**当前这个 value 的时间戳是否比缓存里的 value 的时间戳要新。如果是的话，那么可以写，否则，就不能用旧的数据覆盖新的数据。

###### 解决方案(一) 分布式锁+时间戳

**1.整体技术方案**

这种情况，主要是准备一个分布式锁，大家去抢锁，抢到锁就做set操作。

加锁的目的实际上就是把并行读写改成串行读写的方式，从而来避免资源竞争。

**2.Redis分布式锁的实现**

主要用到的redis函数是setnx()

用SETNX实现分布式锁 使用setnx设置一个公共锁

​	`setnx lock-key value`

利用SETNX非常简单地实现分布式锁。例如：某客户端要获得一个名字youzhi的锁，客户端使用下面的命令进行获取：

SETNX lock.youzhi<current Unix time + lock timeout + 1>

如返回1，则该客户端获得锁，把lock.youzhi的键值设置为时间值表示该键已被锁定，该客户端最后可以通过DEL lock.foo来释放该锁。

如返回0，表明该锁已被其他客户端取得，这时我们可以先返回或进行重试等对方完成或等待锁超时。

**3.时间戳**

由于上面举的例子，要求key的操作需要顺序执行，所以需要保存一个时间戳判断set顺序。

系统A key 1 {ValueA 7:00}

系统B key 1 { ValueB 7:05}

假设系统B先抢到锁，将key1设置为{ValueB 7:05}。接下来系统A抢到锁，发现自己的key1的时间戳早于缓存中的时间戳（7:00<7:05），那就不做set操作了。

**4.什么是分布式锁**

因为传统的加锁的做法（如java的synchronized和Lock）这里没用，只适合单点。因为这是分布式环境，需要的是分布式锁。

当然，分布式锁可以基于很多种方式实现，比如zookeeper、redis等，不管哪种方式实现，基本原理是不变的：用一个状态值表示锁，对锁的占用和释放通过状态值来标识。

###### 解决方案(二) 利用消息队列

在并发量过大的情况下,可以通过消息中间件进行处理,把并行读写进行串行化。

把Redis.set操作放在队列中使其串行化,必须的一个一个执行。

这种方式在一些高并发的场景中算是一种通用的解决方案。

##### Q&A Redis持久化方案

AOF :以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中命令 达到恢复数据的目的。与RDB相比可以简单描述为改记录数据为记录数据产生的过程 （主流方式：具有实时性）

RDB：将某一时刻的快照进行保存。快照形式，定期把内存中当前时刻的数据保存到磁盘。Redis默认支持的持久化方案

###### RDB持久化配置

Redis会将数据集的快照dump到dump.rdb文件中。此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开6379.conf文件之后，我们搜索save，可以看到下面的配置信息：

> save 900 1              #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。
>
> save 300 10            #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。
>
> save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。

###### AOF持久化配置

在Redis的配置文件中存在三种同步方式，它们分别是：

> appendfsync always     #每次有数据修改发生时都会写入AOF文件。
>
> appendfsync everysec  #每秒钟同步一次，该策略为AOF的缺省策略。
>
> appendfsync no          #从不同步。高效但是数据不会被持久化

###### RDB与AOF的选择

一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。

**如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。**

**有很多用户都只使用 AOF 持久化， 但我们并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快， 除此之外， 使用 RDB 还可以避免之前提到的 AOF 程序的 bug 。**

- RDB与AOF的选择实际上是在做一种权衡，每种都有利有弊
- 如不能承受数分钟以内的数据丢失，对业务数据非常敏感，选用AOF 
- 如能承受数分钟以内的数据丢失，且追求大数据集的恢复速度，选用RDB 
- 灾难恢复选用RDB 
- 双保险策略，同时开启 RDB 和 AOF，重启后，Redis优先使用 AOF 来恢复数据，降低丢失数据的量

###### 如何从RDB方式切换为AOF方式：

在 Redis 2.2 或以上版本，可以在不重启的情况下，从 RDB 切换到 AOF ：

- 为最新的 dump.rdb 文件创建一个备份。
- 将备份放到一个安全的地方。
- 执行以下两条命令:
- redis-cli config set appendonly yes
- redis-cli config set save “”
- 确保写命令会被正确地追加到 AOF 文件的末尾。
- 执行的第一条命令开启了 AOF 功能： Redis 会阻塞直到初始 AOF 文件创建完成为止， 之后 Redis 会继续处理命令请求， 并开始将写入命令追加到 AOF 文件末尾。

执行的第二条命令用于关闭 RDB 功能。 这一步是可选的， 如果你愿意的话， 也可以同时使用 RDB 和 AOF 这两种持久化功能。

<font color="red">重要:别忘了在 redis.conf 中打开 AOF 功能！ 否则的话， 服务器重启之后， 之前通过 CONFIG SET 设置的配置就会被遗忘， 程序会按原来的配置来启动服务器。</font>

##### Q&A 数据删除策略

**数据删除策略的目标：**
在内存占用与CPU之间寻找一种平衡，顾此失彼都会造成整体Redis性能的下降，甚至引发服务器宕机或者内存泄漏。

**定时删除**

- 创建一个定时器，当key设置有过期时间，且过期时间到达时，由定时器任务立即执行对键的删除操作
- 优点：节约内存，到期就删除，快速释放掉不必要的内存占用
- 缺点：CPU压力很大，无论CPU此时负载量多高，均占用CPU,会影响redis服务器响应时间和指令吞吐量
- 总结：用处理器性能换取存储空间(拿时间换空间)

**惰性删除**

- 数据到达过期时间，不做处理。等下次访问该数据时
  - 如果未过期，返回数据
  - 发现已过期，删除，返回不存在
- 优点：节约CPU性能，发现必须删除的时候才删除
- 缺点：内存压力很大，出现长期占用内存的数据
- 总结：用存储空间换取处理器性能

**定期删除**

- 周期性轮训redis库中的时效性数据，采用随机抽取的策略，利用过期数据占比的方式控制删除频度
- 特点1：CPU性能占用设置有峰值，检测频度可自定义设置
- 特点2：内存压力不是很大，长期占用内存的冷数据会被持续清理
- 总结：周期性抽查存储空间（随机抽查，重点抽查）

##### Q&A Redis有哪几种数据淘汰策略

1.noeviction:返回错误当内存限制达到，并且客户端尝试执行会让更多内存被使用的命令。 

2.allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。 

3.volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存 放。 

4.allkeys-random: 回收随机的键使得新添加的数据有空间存放。 

5.volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。 

6.volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间 存放。 

##### Q&A 数据逐出策略

**当新数据进入Redis时如果内存不足怎么办？**

Redis使用内存存储数据，在执行每一个命令前，会调用freeMemoryIfNeeded()检测内存是否充足。如果内存不满足新加入数据的最低存储要求，redis要临时删除一些数据为当前指令清理存储空间。清理数据的策略称为逐出算法。

注意：逐出数据的过程不是100%能够清理出足够的可使用的内存空间，如果不成功则反复执行。当对所有数据尝试完毕后，如果不能达到内存清理的要求，将出现错误信息。

##### Q&A  Redis同步机制

Redis的主同步机制可以确保redis的master和slave之间的数据同步。2.8版本以后可以使用psync命令完成主从数据同步。同步机制包括 全量复制和增量复制。

**全量拷贝**

1. slave第一次启动时，连接Master，发送PSYNC命令，格式为psync {runId} {offset}

> {runId} 为master的运行id；{offset}为slave自己的复制偏移量。
> slave第一次连接master时，slave并不知道master的runId，也不知道自己偏移量，这时候slave会传一个问号和-1，告诉master节点是第一次同步。格式为psync ? -1

1. 当master接收到psync ? -1时，知道slave是要全量复制，就会将自己的runId和offset告知slave，回复命令fullresync {runId} {offset}。同时，master会执行bgsave命令来生成rdb文件，期间的所有写命令将被写入缓冲区。

> slave接受到master的回复命令后，会保存master的runId和offset，slave此时处于同步状态。
> slave处于同步状态，如果此时收到请求，当配置参数slave-server-stale-data yes时，会响应当前请求；slave-server-stale-data no，返回错误。

1. master bgsave执行完毕，向slave发送rdb文件。rdb文件发送完毕后，开始向slave发送缓冲区中的写命令。
2. slave收到rdb文件，丢弃所有旧数据，开始载入rdb文件。
3. rdb文件同步结束之后，slave执行从master缓冲区发送过来的所以写命令。
4. 此后 master 每执行一个写命令，就向slave发送相同的写命令。

**增量拷贝**

1. 如果出现网络闪断或者命令丢失等异常情况时，当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行ID。因此会把它们当作psync参数发送给主节点，要求进行部分复制操作，格式为psync {runId} {offset}。
2. 主节点接到psync命令后首先核对参数runId是否与自身一致，如果一致，说明之前复制的是当前主节点；之后根据参数offset在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送+continue响应，表示可以进行部分复制；否则进行全量复制。
3. 主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。

##### Q&A  Redis过期时间和永久有效怎么设置

`PERSIST key`：持久化key

`EXPIRE key seconds:` 为key设置过期时间，以秒计

##### Q&A  Redis如何作内存优化

1、缩减键值对象

　　缩减键（key）和值（value）的长度，

- key长度：如在设计键时，在完整描述业务情况下，键值越短越好。
- value长度：值对象缩减比较复杂，常见需求是把业务对象序列化成二进制数组放入Redis。首先应该在业务上精简业务对象，去掉不必要的属性避免存储无效数据。其次在序列化工具选择上，应该选择更高效的序列化工具来降低字节数组大小。以JAVA为例，内置的序列化方式无论从速度还是压缩比都不尽如人意，这时可以选择更高效的序列化工具，如: protostuff，kryo等，下图是JAVA常见序列化工具空间压缩对比。

2、共享对象池

　　对象共享池指Redis内部维护[0-9999]的整数对象池。创建大量的整数类型redisObject存在内存开销，每个redisObject内部结构至少占16字节，甚至超过了整数自身空间消耗。所以Redis内存维护一个[0-9999]的整数对象池，用于节约内存。 除了整数值对象，其他类型如list,hash,set,zset内部元素也可以使用整数对象池。因此开发中在满足需求的前提下，尽量使用整数对象以节省内存。

3、字符串优化

4、编码优化

5、控制key的数量

##### Q&A Redis 集群的主从复制模型是怎样的？ 

为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型, 每个节点都会有 N-1 个复制品. 

##### Q&A Redis 集群会有写操作丢失吗？为什么？ 

Redis 并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。 

##### Q&A Redis 集群之间是如何复制的？ 

异步复制 

##### Q&A Redis 集群最大节点个数是多少？ 

16384 个 

##### Q&A Redis 集群如何选择数据库？ 

Redis 集群目前无法做数据库选择，默认在 0 数据库。 

##### Q&A Redis 中的管道有什么用？ 

一次请求/响应服务器能实现处理新的请求即使旧的请求还未被响应，这样就可以将多个命令发送到服务 器，而不用等待回复，最后在一个步骤中读取该答复。 

这就是管道（pipelining），是一种几十年来广泛使用的技术。例如许多 POP3 协议已经实现支持这个功能，大大加快了从服务器下载新邮件的过程。

##### Q&A 怎么理解 Redis 事务？ 

事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行，事务在执行的过程中，不会 被其他客户端发送来的命令请求所打断。 

事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。 

##### Q&A Redis 事务相关的命令有哪几个？ 

MULTI、EXEC、DISCARD、WATCH 

##### Q&A Redis 分布式锁如何使用

先拿 setnx 来争抢锁，抢到之后，再用 expire 给锁加一个过期时间防止锁忘记了释放。 

如果在 setnx 之后执行 expire 之前进程意外 crash 或者要重启维护了，那会怎么样？ 

set 指令有非常复杂的参数，这个应该是可以同时把 setnx 和 expire 合成一条指令来用的！

##### Q&A Redis做异步队列用过吗如何使用的

一般使用list结构作为队列，rpush生产消费，lpop消费消息，当lpop没有消息的时候要适当sleep一会再重试。

缺点：在消费者下线时会产生消息丢失，要使用专业的消息队列。


### JVM

### JUC



