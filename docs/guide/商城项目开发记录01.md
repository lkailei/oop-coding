---
title: 宜立方商城项目
autoGroup-5: 项目篇
---
# 基于宜立方商城项目开发记录问题

## 分布式架构

分布式架构是 [分布式计算技术](https://baike.baidu.com/item/分布式计算技术/2354717)的应用和工具，目前成熟的[技术](https://baike.baidu.com/item/技术/832247)包括J2EE, CORBA和.NET(DCOM)，这些技术牵扯的内容非常广，相关的技术，相关的书籍也非常多，本文不介绍这些技术的内容，也没有涉及这些技术的细节，只是从各种分布式系统平台产生的背景和在软件开发中应用的情况来探讨它们的主要异同。

需要按照功能点把系统拆分，拆分成独立的功能。单独为某一个节点添加服务器。需要系统之间配合才能完成整个业务逻辑。叫做**分布式**

把系统按照模块拆分成多个子系统。

**优点：**

1. 把模块拆分，使用接口通信，降低模块之间的耦合度。
2. 把项目拆分成若干个子项目，不同的团队负责不同的子项目。
3. 增加功能时只需要再增加一个子项目，调用其他系统的接口就可以。
4. 可以灵活的进行分布式部署。

**缺点：**

1. 系统之间交互需要使用远程通信，接口开发增加工作量。
2. 各个模块有一些通用的业务逻辑无法共用。



## 分布式架构演进

[图解分布式架构演进](https://www.cnblogs.com/dump/p/8125539.html)



## SOA架构

SOA：Service Oriented Architecture面向服务的架构。也就是把工程拆分成服务层、表现层两个工程。服务层中包含业务逻辑，只需要对外提供服务即可。表现层只需要处理和页面的交互，业务逻辑都是调用服务层的服务来实现

### 架构特点

**系统集成：** 站在系统的角度，解决企业系统间的通信问 题，把原先散乱、无规划的系统间的网状结构，梳理成 规整、可治理的系统间星形结构，这一步往往需要引入 一些产品，比如 ESB、以及技术规范、服务管理规范； 这一步解决的核心问题是【有序】

**系统的服务化：** 站在功能的角度，把业务逻辑抽象成 可复用、可组装的服务，通过服务的编排实现业务的 快速再生，目的：把原先固有的业务功能转变为通用 的业务服务，实现业务逻辑的快速复用；这一步解决 的核心问题是【复用】

**业务的服务化：** 站在企业的角度，把企业职能抽象成 可复用、可组装的服务；把原先职能化的企业架构转变为服务化的企业架构，进一步提升企业的对外服务能力；“前面两步都是从技术层面来解决系统调用、系统功能复用的问题”。第三步，则是以业务驱动把一个业务单元封装成一项服务。这一步解决的核心问题是【高效】

## Dubbo与Zookeeper

**单一应用架构**

> 当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的 数据访问框架(ORM) 是关键。

**垂直应用架构**

> 当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的 Web框架(MVC) 是关键。

**分布式服务架构**

> 当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的 分布式服务框架(RPC) 是关键。

**流动计算架构**

> 当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的 资源调度和治理中心(SOA) 是关键。

### Dubbo

Dubbo是  阿里巴巴公司开源的一个高性能优秀的服务框架，使得应用可通过高性能的 RPC 实现服务的输出和输入功能，可以和  Spring框架无缝集成。

Dubbo是一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。为了实现不同系统之间的通信

**主要核心部件：**

- Remoting:网路通讯框架，实现了sync-over-async和request-response消息机制
- RPC: 一个远程过程调用的抽象，支持负载均衡、容灾和集群功能
- Registry: 服务目录框架用于服务的注册和服务事件发布和订阅

Dubbo就是资源调度和治理中心的管理工具。

#### Dubbo使用

```xml
先要在注册中心注册(注册中心)：ZooKeeper使用
发布服务：
<!-- 和本地服务一样实现远程服务 -->
<bean id="xxxService" class="com.xxx.XxxServiceImpl" />
<!-- 增加暴露远程服务配置 -->
<dubbo:service interface="com.xxx.XxxService" ref="xxxService" />

调用服务：
<!-- 增加引用远程服务配置 -->
<dubbo:reference id="xxxService" interface="com.xxx.XxxService" />
<!-- 和本地服务一样使用远程服务 -->
<bean id="xxxAction" class="com.xxx.XxxAction">
<property name="xxxService" ref="xxxService" />
</bean>
dubbo使用只需要把jar包放到tomcat中
```

### Zookeeper

注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小。使用dubbo-2.3.3以上版本，建议使用zookeeper注册中心。Zookeeper是Apacahe Hadoop的子项目，是一个树型的目录服务，支持变更推送，适合作为Dubbo服务的注册中心，工业强度较高，可用于生产环境，并推荐使用.

> 可以作为集群的管理工具使用.可以集中管理配置文件

#### 安装步骤

第一步：安装jdk

第二步：把zookeeper的压缩包上传到linux系统。

第三步：解压缩压缩包 tar -zxvf zookeeper-3.4.6.tar.gz	

第四步：进入zookeeper-3.4.6目录，创建data文件夹。

第五步：把zoo_sample.cfg改名为zoo.cfg

> [root@localhost conf]# mv zoo_sample.cfg zoo.cfg
> 											tickTime = 2000
> 											dataDir = /path/to/zookeeper/data
> 											clientPort = 2181
> 											initLimit = 5
> 											syncLimit = 2

第六步：修改data属性：`dataDir=/root/zookeeper-3.4.6/data`

第七步：启动zookeeper  `[root@localhost bin]# ./zkServer.sh start`

关闭：`[root@localhost bin]# ./zkServer.sh stop`

查看状态：`[root@localhost bin]# ./zkServer.sh status`

注意：需要关闭防火墙。service iptables stop。永久关闭修改配置开机不启动防火墙：chkconfig iptables off

如果不能成功启动zookeeper，需要删除data目录下的zookeeper_server.pid文件。

## PageHelper

如果你也在用 MyBatis，建议尝试该分页插件，这一定是最方便使用的分页插件。分页插件支持任何复杂的单表、多表分页.

### 使用方法

1.把pageHelper依赖的jar包添加到工程中,

```xml
<dependency>
	<groupId>com.github.pagehelper</groupId>
	<artifactId>pagehelper</artifactId>
	<version>最新版本</version>
</dependency>				
```

2.在sqlMapConfig.xml配置

```xml
<configuration>
	<plugins>
		 <!-- com.github.pagehelper为PageHelper类所在包名 -->
		<plugin interceptor="com.github.pagehelper.PageHelper">
		<!-- 使用下面的方式配置参数，后面会有所有的参数介绍 -->
		<!-- 设置数据库类型 Oracle,Mysql,MariaDB,SQLite,Hsqldb,PostgreSQL六种数据库-->        
		<property name="dialect" value="mysql"/>
		</plugin>					
	</plugins>
</configuration>
```

**在配置property时可以配置以下参数和value**

helperDialect：分页插件会自动检测当前的数据库链接，自动选择合适的分页方式。 你可以配置helperDialect属性来指定分页插件使用哪种方言。配置时，可以使用下面的缩写值oracle,mysql,mariadb,sqlite,hsqldb,postgresql,db2,sqlserver,informix,h2,sqlserver2012,derby 特别注意：使用 SqlServer2012 数据库时，需要手动指定为 sqlserver2012，否则会使用 SqlServer2005 的方式进行分页。你也可以实现 AbstractHelperDialect，然后配置该属性为实现类的全限定名称即可使用自定义的实现方法。

offsetAsPageNum：默认值为 false，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为 true 时，会将 RowBounds 中的 offset 参数当成 pageNum 使用，可以用页码和页面大小两个参数进行分页。

rowBoundsWithCount：默认值为false，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为true时，使用 RowBounds 分页会进行 count 查询。

pageSizeZero：默认值为 false，当该参数设置为 true 时，如果 pageSize=0 或者 RowBounds.limit = 0 就会查询出全部的结果（相当于没有执行分页查询，但是返回结果仍然是 Page 类型）。

reasonable：分页合理化参数，默认值为false。当该参数设置为 true 时，pageNum<=0 时会查询第一页， pageNum>pages（超过总数时），会查询最后一页。默认false 时，直接根据参数进行查询。

params：为了支持startPage(Object params)方法，增加了该参数来配置参数映射，用于从对象中根据属性名取值， 可以配置 pageNum,pageSize,count,pageSizeZero,reasonable，不配置映射的用默认值， 默认值为pageNum=pageNum;pageSize=pageSize;count=countSql;reasonable=reasonable;pageSizeZero=pageSizeZero。

supportMethodsArguments：支持通过 Mapper 接口参数来传递分页参数，默认值false，分页插件会从查询方法的参数值中，自动根据上面 params 配置的字段中取值，查找到合适的值时就会自动分页。 使用方法可以参考测试代码中的 com.github.pagehelper.test.basic 包下的 ArgumentsMapTest 和 ArgumentsObjTest。

autoRuntimeDialect：默认值为 false。设置为 true 时，允许在运行时根据多数据源自动识别对应方言的分页 （不支持自动选择sqlserver2012，只能使用sqlserver），用法和注意事项参考下面的场景五。

closeConn：默认值为 true。当使用运行时动态数据源或没有设置 helperDialect 属性自动获取数据库类型时，会自动获取一个数据库连接， 通过该属性来设置是否关闭获取的这个连接，默认true关闭，设置为 false 后，不会关闭获取的连接，这个参数的设置要根据自己选择的数据源来决定。

3.在spring配置拦截器插件

```xml
<bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean">
    <!-- 注意其他配置 -->
    <property name="plugins">
        <array>
            <bean class="com.github.pagehelper.PageInterceptor">
                <property name="properties">
                    <!--使用下面的方式配置参数，一行配置一个 -->
                    <value>
                    params=value1
                    </value>
                </property>
            </bean>
        </array>
    </property>
</bean>
```

4.代码中使用

```java

/**
*1、设置分页信息：
*/
//获取第1页，10条内容，默认查询总数count
PageHelper.startPage(1, 10);

//紧跟着的第一个select方法会被分页
List<Country> list = countryMapper.selectIf(1);
/**
*2、取分页信息
*/
//分页后，实际返回的结果list类型是Page<E>，如果想取出分页信息，需要强制转换为Page<E>，
Page<Country> listCountry = (Page<Country>)list;
listCountry.getTotal();
/**
*3、取分页信息的第二种方法
*/
//获取第1页，10条内容，默认查询总数count
PageHelper.startPage(1, 10);
List<Country> list = countryMapper.selectAll();
//用PageInfo对结果进行包装
PageInfo page = new PageInfo(list);
//测试PageInfo全部属性
//PageInfo包含了非常全面的分页属性
assertEquals(1, page.getPageNum());
assertEquals(10, page.getPageSize());
assertEquals(1, page.getStartRow());
assertEquals(10, page.getEndRow());
assertEquals(183, page.getTotal());
assertEquals(19, page.getPages());
assertEquals(1, page.getFirstPage());
assertEquals(8, page.getLastPage());
assertEquals(true, page.isFirstPage());
assertEquals(false, page.isLastPage());
assertEquals(false, page.isHasPreviousPage());
assertEquals(true, page.isHasNextPage());
```

## Nginx

Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好。官方测试nginx能够支支撑5万并发链接，并且cpu、内存等资源消耗却非常低，运行非常稳定。

Nginx既可以在内部的直接支持Rails和PHP程序对外进行服务,也可以支持HTTP代理服务对外进行服务，采用C语言编写,处理静态文件，索引文件以及自动索引;打开文件描述符缓冲。无缓存的反向代理加速，简单的负载均衡和容错。FastCGI，简单的负载均衡和容错。模块化的结构。包括 gzipping, byte ranges, chunked responses,以及 SSI-filter 等 filter。如果由 FastCG或其它代理服务器处理单页中存在的多个 SSI，则这项处理可以并行运行，而不需要相互等待。支持 SSL 和 TLSSNI。

### Nginx可以作什么

1. http服务器。Nginx是一个http服务可以独立提供http服务。可以做网页静态服务器。
2. 虚拟主机。可以实现在一台服务器虚拟出多个网站。例如个人网站使用的虚拟主机。
3. 反向代理，负载均衡。当网站的访问量达到一定程度后，单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用nginx做反向代理。并且多台服务器可以平均分担负载，不会因为某台服务器负载高宕机而某台服务器闲置的情况

### Nginx实现反向代理



### Nginx负载均衡策略

1. **weight轮训（默认）**：接收到的请求按照顺序逐一分配到不同的后端服务器，如果某个服务器拓机的情况下，nginx会将其剔除队列，请求受理情况不会受到影响，可以给不同的后端服务配置权重值，用于调整不同的服务器上请求的分配率，权重越大被分配到的请求的几率越大。
2. **ip_hash :** 每个请求按照发起客户端的ip的hash结果进行匹配，这样的算法下一个固定ip地址的客户端总会访问到同一个后端服务器，这也在一定程度上解决了集群部署环境下session共享的问题
3. **fair**：智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配，响应时间短处理效率高的服务器分配到请求的概率高，响应时间长处理效率低的服务器分配到的请求少；结合了前两者的优点的一种调度算法。但是需要注意的是nginx默认不支持fair算法，如果要使用这种调度算法，请安装upstream_fair模块
4. **url_hash**：按照访问的url的hash结果分配请求，每个请求的url会指向后端固定的某个服务器，可以在nginx作为静态服务器的情况下提高缓存效率。同样要注意nginx默认不支持这种调度算法，要使用的话需要安装nginx的hash软件包

## FastDFS

FastDFS是一个开源的轻量级分布式文件系统，它对文件进行管理，功能包括：文件存储、文件同步、文件访问（文件上传、文件下载）等，解决了大容量存储和负载均衡的问题。特别适合以文件为载体的在线服务，如相册网站、视频网站等等。

FastDFS为互联网量身定制，充分考虑了冗余备份、负载均衡、线性扩容等机制，并注重高可用、高性能等指标，使用FastDFS很容易搭建一套高性能的文件服务器集群提供文件上传、下载等服务。

FastDFS服务端主要有：跟踪器(tracker)群和存储节点(storage)，跟踪器做调度工作，在访问上起负载均衡的作用，跟踪器和存储节点都可以由一台或多台服务器构成。跟踪器和存储节点中的服务器均可以随时增加或下线而不会影响线上服务。其中跟踪器中的所有服务器都是对等的，可以根据服务器的压力情况随时增加或减少。

### 上传交互过程

1. client询问tracker上传到的storage，不需要附加参数；
2.  tracker返回一台可用的storage；
3.  client直接和storage通讯完成文件上传。

### 下载交互过程

1. client询问tracker下载文件的storage，参数为文件标识（卷名和文件名）；
2.  tracker返回一台可用的storage；
3.  client直接和storage通讯完成文件下载。

需要说明的是，client为使用FastDFS服务的调用方，client也应该是一台服务器，它对tracker和storage的调用均为服务器间的调用。

### 安装方式

### 使用

**加入maven 依赖：**

```xml
<!-- https://mvnrepository.com/artifact/com.github.tobato/fastdfs-client -->
<dependency>
    <groupId>com.github.tobato</groupId>
    <artifactId>fastdfs-client</artifactId>
    <version>1.27.2</version>
</dependency>
```

**java代码如下：**

```java
@Test
    public void testUpload() throws Exception, MyException {
        //trackerserver的服务器端口号为22122
        //创建一个配置文件，文件名任意，内容就是tracker服务器的地址
        //使用全局对象加载配置文件(必须是绝对路径)
        ClientGlobal.init("F:\\Java\\javaEE/e3-manager-web/src/main/resources/conf/client.conf");
        //创建一个TrackerClient对象
        TrackerClient trackerClient=new TrackerClient();
        //通过TrackerClient获得TrackerServer对象
        TrackerServer trackerServer=trackerClient.getConnection();
        //创建一个引用的StorageServer的引用可以为null
        StorageServer storageServer=null;
        //创建一个StoreageClient参数需要TrackerServer和StorageServer
        StorageClient storageClient=new StorageClient(trackerServer,storageServer);
        //使用StorageClient上传文件(必须为绝对路径)
        String[] upload_file = storageClient.upload_file("/.jpg","jpg", null);
        for(String string :upload_file) {
            System.out.println(string);
        }
    }


    private
    /**
     * 用工具类的方式测试
     * @throws Exception
     */
    public void testFastDfsClient() throws Exception {
        FastDFSClient fastDFSClient=new FastDFSClient("F:\\Java\\javaEE/e3-manager-web/src/main/resources/conf/client.conf");
        String string=fastDFSClient.uploadFile("////.jpg");
        System.out.println(string);
    }
					使用工具类上传，需要建立文件夹，然后通过文件的使用需要配置value()
/**
 * 图片上传的
 * @author leoill
 *TODO
 *2019年1月6日
 */
@Controller
public class PictureController {

    @Value("IMAGE_SERVER")
    private String IMAGE_URL;

    @RequestMapping("/pic/upload")
    @ResponseBody
    public String uploadFile(MultipartFile uploadFile){
        //返回String对象时直接返回的是contentType="text/plain"
        //把图片上传到服务器
        try {
            FastDFSClient fastDFSClient=new FastDFSClient("classpath:conf/client.conf");
            //取出扩展名
            String originalFilename = uploadFile.getOriginalFilename();
            //originalFilename.substring(originalFilename.lastIndexOf(".")+1)
            //返回一个图片的地址和文件名
            String url = fastDFSClient.uploadFile(uploadFile.getBytes(), originalFilename.substring(originalFilename.lastIndexOf(".")+1));
            //补充完整的URL
            url=IMAGE_URL+url;
            //封装到map
            Map<String, Object> map=new HashMap<>();
            map.put("error", 0);
            map.put("url", url);
            return JsonUtils.objectToJson(map);
        } catch (Exception e) {
            // TODO Auto-generated catch block
            e.printStackTrace();
            Map<String, Object> map=new HashMap<>();
            map.put("error", 1);
            map.put("message", "图片上传失败");
            return JsonUtils.objectToJson(map);
        }

```

## ActiveMQ

消息队列，是一个完全支持JMS1.1和J2EE规范的JMS Provider实现。

ActiveMQ 是Apache出品，最流行的，能力强劲的开源消息总线。ActiveMQ 是一个完全支持JMS1.1和J2EE 1.4规范的 JMS Provider实现,尽管JMS规范出台已经是很久的事情了,但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。

### 主要特点

1. 多种语言和协议编写客户端。语言: Java, C, C++, C#, Ruby, Perl, Python, PHP。应用协议: OpenWire,Stomp REST,WS Notification,XMPP,AMQP
2. 完全支持JMS1.1和J2EE 1.4规范 (持久化,XA消息,事务)
3. 对Spring的支持,ActiveMQ可以很容易内嵌到使用Spring的系统里面去,而且也支持Spring2.0的特性
4. 通过了常见J2EE服务器(如 Geronimo,JBoss 4, GlassFish,WebLogic)的测试,其中通过JCA 1.5 resource adaptors的配置,可以让ActiveMQ可以自动的部署到任何兼容J2EE 1.4 商业服务器上
5.  支持多种传送协议:in-VM,TCP,SSL,NIO,UDP,JGroups,JXTA
6. 支持通过JDBC和journal提供高速的消息持久化
7.  从设计上保证了高性能的集群,客户端-服务器,点对点
8. 支持Ajax
9. 支持与Axis的整合
10. 可以很容易得调用内嵌JMS provider,进行测试

### java测试代码

```java
    public void testQueueProducer() throws Exception {
        // 第一步：创建ConnectionFactory对象，需要指定服务端ip及端口号。
        //brokerURL服务器的ip及端口号
        ConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp://192.168.25.168:61616");
        // 第二步：使用ConnectionFactory对象创建一个Connection对象。
        Connection connection = connectionFactory.createConnection();
        // 第三步：开启连接，调用Connection对象的start方法。
        connection.start();
        // 第四步：使用Connection对象创建一个Session对象。
        //第一个参数：是否开启事务。true：开启事务，第二个参数忽略。
        //第二个参数：当第一个参数为false时，才有意义。消息的应答模式。1、自动应答2、手动应答。一般是自动应答。
        Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);
        // 第五步：使用Session对象创建一个Destination对象（topic、queue），此处创建一个Queue对象。
        //参数：队列的名称。
        Queue queue = session.createQueue("test-queue");
        // 第六步：使用Session对象创建一个Producer对象。
        MessageProducer producer = session.createProducer(queue);
        // 第七步：创建一个Message对象，创建一个TextMessage对象。
					/*TextMessage message = new ActiveMQTextMessage();
					message.setText("hello activeMq,this is my first test.");*/
        TextMessage textMessage = session.createTextMessage("hello activeMq,this is my first test.");
        // 第八步：使用Producer对象发送消息。
        producer.send(textMessage);
        // 第九步：关闭资源。
        producer.close();
        session.close();
        connection.close();
    }
    public void testQueueConsumer() throws Exception {
        // 第一步：创建一个ConnectionFactory对象。
        ConnectionFactory connectionFactory = new ActiveMQConnectionFactory("tcp://192.168.25.168:61616");
        // 第二步：从ConnectionFactory对象中获得一个Connection对象。
        Connection connection = connectionFactory.createConnection();
        // 第三步：开启连接。调用Connection对象的start方法。
        connection.start();
        // 第四步：使用Connection对象创建一个Session对象。
        Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);
        // 第五步：使用Session对象创建一个Destination对象。和发送端保持一致queue，并且队列的名称一致。
        Queue queue = session.createQueue("test-queue");
        // 第六步：使用Session对象创建一个Consumer对象。
        MessageConsumer consumer = session.createConsumer(queue);
        // 第七步：接收消息。
        consumer.setMessageListener(new MessageListener() {

            @Override
            public void onMessage(Message message) {
                try {
                    TextMessage textMessage = (TextMessage) message;
                    String text = null;
                    //取消息的内容
                    text = textMessage.getText();
                    // 第八步：打印消息。
                    System.out.println(text);
                } catch (JMSException e) {
                    e.printStackTrace();
                }
            }
        });
        //等待键盘输入
        System.in.read();
        // 第九步：关闭资源
        consumer.close();
        session.close();
        connection.close();
    }
```

### ActiveMQ整合Spring

#### applicationContext.xml

```xml
<beans>
  <!-- 真正可以产生Connection的ConnectionFactory，由对应的 JMS服务厂商提供 -->
  <bean id="targetConnectionFactory" class="org.apache.activemq.ActiveMQConnectionFactory">
    <property name="brokerURL" value="tcp://192.168.25.168:61616" />
  </bean>
  <!-- Spring用于管理真正的ConnectionFactory的ConnectionFactory -->
  <bean id="connectionFactory"
        class="org.springframework.jms.connection.SingleConnectionFactory">
    <!-- 目标ConnectionFactory对应真实的可以产生JMS Connection的ConnectionFactory -->
    <property name="targetConnectionFactory" ref="targetConnectionFactory" />
  </bean>
  <!--这个是队列目的地，点对点的 -->
  <bean id="queueDestination" class="org.apache.activemq.command.ActiveMQQueue">
    <constructor-arg>
      <value>spring-queue</value>
    </constructor-arg>
  </bean>
  <!--这个是主题目的地，一对多的 -->
  <bean id="topicDestination" class="org.apache.activemq.command.ActiveMQTopic">
    <constructor-arg value="topic" />
  </bean>
  <!-- 接收消息 -->
  <!-- 配置监听器 -->
  <bean id="myMessageListener" class="cn.e3mall.search.listener.MyMessageListener" />
  <!-- 消息监听容器 -->
  <bean class="org.springframework.jms.listener.DefaultMessageListenerContainer">
    <property name="connectionFactory" ref="connectionFactory" />
    <property name="destination" ref="queueDestination" />
    <property name="messageListener" ref="myMessageListener" />
  </bean>
</beans>
```

#### java代码

```java
// 生产者
public void testQueueProducer() throws Exception {
        // 第一步：初始化一个spring容器
        ApplicationContext applicationContext = new ClassPathXmlApplicationContext("classpath:spring/applicationContext-activemq.xml");
        // 第二步：从容器中获得JMSTemplate对象。
        JmsTemplate jmsTemplate = applicationContext.getBean(JmsTemplate.class);
        // 第三步：从容器中获得一个Destination对象
        Queue queue = (Queue) applicationContext.getBean("queueDestination");
        // 第四步：使用JMSTemplate对象发送消息，需要知道Destination
        jmsTemplate.send(queue, new MessageCreator() {

            @Override
            public Message createMessage(Session session) throws JMSException {
                TextMessage textMessage = session.createTextMessage("spring activemq test");
                return textMessage;
            }
        });
}
//接受消息：
public class MyMessageListener implements MessageListener {
    @Override
    public void onMessage(Message message) {
        try {
            TextMessage textMessage = (TextMessage) message;
            //取消息内容
            String text = textMessage.getText();
            System.out.println(text);
        } catch (JMSException e) {
            e.printStackTrace();
        }
    }

}
```



## Redis

Redis:是一个高性能的key-value的数据库，支持数据的持久化，提供不同类型的数据结构存储，支持数据备份.支持以下类型：字符型，散列型，列表型list，集合型set，有序集合型sort set。

Redis有着更为复杂的数据结构并且提供对他们的原子性操作，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。

Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。

### 使用redis的目的

在项目中主要用来用作数据的缓存，将数据缓存在redis中，减轻对底层数据库的访问压力，获得更高的并发和更快的请求响应速度

使用缓存之后，大量的查询语句就从原来的数据库服务器中，转移到了高效的Redis服务器中执行，这将在很大程度上减轻原来数据库服务器的压力，并且提升查询的反应速度和效率。所以在很大的程度上，系统性能就得到了很好的改善。

（1）高性能

​		比如说有一个很复杂的sql数据查询，这个查询要耗费大量的时间，如果每次都直接取数据查询，那必然会对请求响应时间造成很大的影响，如果能在第一次查询完毕之后，将其直接保存在缓存当中，下次查询的时候，直接在缓存中拿走现成的数据，这样就会大大缩短请求的响应时间。

（2）高并发

​		我们知道数据库能承受的并发是有限的，那么在流量高峰期(比如，抢购、打折、秒杀等等)，会有大量的请求进入我们的系统，比如查询某个商品的详情，如果我们没有缓冲，那么给次查询都要走数据库，假如我们的数据库每秒只能接受2000个请求，结果一秒钟进来了5000个请求，那么数据库就直接崩掉了，毫无高并发可言，而如果我们中间具有缓存服务，那么在第一个用户查询商品详情时(或者提前将放好)我们可以直接将商品的详情信息数据放到缓存里面，这样在后续用户查询时就可以直接走缓存，不走数据库，缓存是基于内存的，它的访问速度快，并发高；因此就可以提供一个高并发的支持。

### linux下安装redis:

```
$ wget http://download.redis.io/releases/redis-3.0.0.tar.gz
$ tar xzf redis-3.0.0.tar.gz
$ cd redis-3.0.0
$ make
```

make完后 redis-2.8.17目录下会出现编译后的redis服务程序redis-server,还有用于测试的客户端程序redis-cli,两个程序位于安装目录 src 目录下：

**启动redis服务：**

```
下面启动redis服务.进入redis的安装目录
方式一：
$ cd src
$ ./redis-server
注意这种方式启动redis 使用的是默认配置。也可以通过启动参数告诉redis使用指定配置文件使用下面命令启动。
方式二：
$ cd src
$ ./redis-server ../redis.conf
redis.conf 是一个默认的配置文件。我们可以根据需要使用自己的配置文件。
```

启动redis服务进程后，就可以使用测试客户端程序redis-cli和redis服务交互了。 比如：

```livescript
$ cd src
$ ./redis-cli
redis> set foo bar
OK
redis> get foo
"bar"
```

### Redis持久化方案

#### RDB&AOF

> RDB：快照形式，定期把内存中当前时刻的数据保存到磁盘。Redis默认支持的持久化方案。
>
> AOF形式：把所有对数据库操作的命令，增删改操作的命令。保存到文件中。数据库恢复时把所有的命令执行一遍即可

- RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储.
- AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大.
- 如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式.
- 你也可以同时开启两种持久化方式, 在这种情况下, 当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整.

#### RDB持久化配置

Redis会将数据集的快照dump到dump.rdb文件中。此外，我们也可以通过配置文件来修改Redis服务器dump快照的频率，在打开6379.conf文件之后，我们搜索save，可以看到下面的配置信息：

> save 900 1              #在900秒(15分钟)之后，如果至少有1个key发生变化，则dump内存快照。
>
> save 300 10            #在300秒(5分钟)之后，如果至少有10个key发生变化，则dump内存快照。
>
> save 60 10000        #在60秒(1分钟)之后，如果至少有10000个key发生变化，则dump内存快照。

#### AOF持久化配置

在Redis的配置文件中存在三种同步方式，它们分别是：

> appendfsync always     #每次有数据修改发生时都会写入AOF文件。
>
> appendfsync everysec  #每秒钟同步一次，该策略为AOF的缺省策略。
>
> appendfsync no          #从不同步。高效但是数据不会被持久化

### Redis-cluster架构

1. 所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽.

2. 节点的fail是通过集群中超过半数的节点检测失效时才生效.

3. 客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可

4. redis-cluster把所有的物理节点映射到[0-16383]slot上,cluster 负责维护node<->slot<->value

   Redis 集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对 key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点

## 购物车功能

实现购车商品数据同步：

1. 要求用户登录。
2. 把购物车商品列表保存到数据库中。推荐使用redis。
3. Key：用户id，value：购车商品列表。推荐使用hash，hash的field：商品id，value：商品信息。
4. 在用户未登录情况下写cookie。当用户登录后，访问购物车列表时，
   1. 把cookie中的数据同步到redis。
   2. 把cookie中的数据删除
   3. 展示购物车列表时以redis为准。
   4. 如果redis中有数据cookie中也有数据，需要做数据合并。相同商品数量相加，不同商品添加一个新商品。
5. 如果用户登录状态，展示购物车列表以redis为准。如果未登录，以cookie为准

### 代码实现

```java
    @Value("${TT_CART}")
    private String TT_CART;
    @Value("${CART_EXPIRE}")
    private Integer CART_EXPIRE;

    @Autowired
    private ItemService itemService;

    @RequestMapping("/cart/add/{itemId}")
    public String addCartItem(@PathVariable Long itemId, Integer num,
                              HttpServletRequest request, HttpServletResponse response) {
        // 1、从cookie中查询商品列表。
        List<TbItem> cartList = getCartList(request);
        // 2、判断商品在商品列表中是否存在。
        boolean hasItem = false;
        for (TbItem tbItem : cartList) {
            //对象比较的是地址，应该是值的比较
            if (tbItem.getId() == itemId.longValue()) {
                // 3、如果存在，商品数量相加。
                tbItem.setNum(tbItem.getNum() + num);
                hasItem = true;
                break;
            }
        }
        if (!hasItem) {
            // 4、不存在，根据商品id查询商品信息。
            TbItem tbItem = itemService.getItemById(itemId);
            //取一张图片
            String image = tbItem.getImage();
            if (StringUtils.isNoneBlank(image)) {
                String[] images = image.split(",");
                tbItem.setImage(images[0]);
            }
            //设置购买商品数量
            tbItem.setNum(num);
            // 5、把商品添加到购车列表。
            cartList.add(tbItem);
        }
        // 6、把购车商品列表写入cookie。
        CookieUtils.setCookie(request, response, TT_CART, JsonUtils.objectToJson(cartList), CART_EXPIRE, true);
        return "cartSuccess";
    }

    /**
     * 从cookie中取购物车列表
     * <p>Title: getCartList</p>
     * <p>Description: </p>
     * @param request
     * @return
     */
    private List<TbItem> getCartList(HttpServletRequest request) {
        //取购物车列表
        String json = CookieUtils.getCookieValue(request, TT_CART, true);
        //判断json是否为null
        if (StringUtils.isNotBlank(json)) {
            //把json转换成商品列表返回
            List<TbItem> list = JsonUtils.jsonToList(json, TbItem.class);
            return list;
        }
        return new ArrayList<>();
    }

    @RequestMapping("/cart/cart")
    public String showCartList(HttpServletRequest request, Model model) {
        //取购物车商品列表
        List<TbItem> cartList = getCartList(request);
        //传递给页面
        model.addAttribute("cartList", cartList);
        return "cart";
    }
}
//删除购物车
@RequestMapping("/cart/delete/{itemId}")
public String deleteCartItem(@PathVariable Long itemId, HttpServletRequest request,
        HttpServletResponse response) {
        // 1、从url中取商品id
        // 2、从cookie中取购物车商品列表
        List<TbItem> cartList = getCartList(request);
        // 3、遍历列表找到对应的商品
        for (TbItem tbItem : cartList) {
            if (tbItem.getId() == itemId.longValue()) {
            // 4、删除商品。
            cartList.remove(tbItem);
            break;
            }
        }
            // 5、把商品列表写入cookie。
            CookieUtils.setCookie(request, response, TT_CART, JsonUtils.objectToJson(cartList), CART_EXPIRE, true);
            // 6、返回逻辑视图：在逻辑视图中做redirect跳转。
            return "redirect:/cart/cart.html";
        }   
```

## 出现的问题

**1.在使用maven整合mybatis时出现数据绑定错误：org.apache.ibatis.binding.BindingException: Invalid bound statement (not found)**

解释：就是说，你的Mapper接口，被Spring注入后，却无法正常的使用mapper.xml的sql；这里的Spring注入后的意思是，你的接口已经成功的被扫描到，但是当Spring尝试注入一个代理（MyBatist实现）的实现类后，却无法正常使用。这里的可能发生的情况有如下几种：

接口已经被扫描到，但是代理对象没有找到，即使尝试注入，也是注入一个错误的对象（可能就是null）

接口已经被扫描到，代理对象找到了，也注入到接口上了，但是调用某个具体方法时，却无法使用（可能别的方法是正常的）

**当然，我们不好说是那种情况，毕竟报错的结果是一样的，这里就提供几种排查方法：**

**mapper接口和mapper.xml是否在同一个包（package)下？名字是否一样（仅后缀不同）？**

> 比如，接口名是NameMapper.java;对应的xml就应该是NameMapper.xml

**mapper.xml的命名空间（namespace）是否跟mapper接口的包名一致？**

> 比如，你接口的包名是com.abc.dao,接口名是NameMapper.java，那么你的mapper.xml的namespace应该是com.abc.dao.NameMapper

**接口的方法名，与xml中的一条sql标签的id一致?**

> 比如，接口的方法`List<User> findAll();`那么，对应的xml里面一定有一条是<select id="findAll" resultMap="**"></select>

> 如果接口中的返回值List集合（不知道其他集合也是），那么xml里面的配置，尽量用resultMap（保证resultMap配置正确）,不要用resultType

> 最后，如果你的项目是maven项目，请你在编译后，到接口所在目录看一看，很有可能是没有生产对应的xml文件，因为maven默认是不编译的，因此，你需要在你的pom.xml的`<build></build>`里面，加这么一段：

```xml
<resources>
    <resource>
        <directory>src/main/java</directory>
        <includes>
        	<include>**/*.xml</include>
        </includes>
        <filtering>true</filtering>
    </resource>
</resources>					
```

**2.使用tomcat7插件时运行时出错：org.springframework.beans.factory.BeanDefinitionStoreException: Unexpected exception parsing XML document from file [F:\Java\javaEE\e3-manager\e3-manager-service\target\classes\spring\applicationContext-service.xml]; nested exception is java.lang.IllegalStateException: Context namespace element 'component-scan' and its parser class [org.springframework.context.annotation.ComponentScanBeanDefinitionParser] are only available on JDK 1.5 and higher**
		解决方法：配置出JAVA的编译版本为1.8

```xml
<!-- java编译插件 -->
<plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-compiler-plugin</artifactId>
    <version>3.7.0</version>
    <configuration>
        <source>1.8</source>
        <target>1.8</target>
        <encoding>UTF-8</encoding>
    </configuration>
</plugin>
```

**3.在pom.xml中配置出现：web.xml is missing and `<failOnMissingWebXml>` is set to true这个意思就是未能够在webapps下的目录没有web.xml**

直接这时候需要右击项目——>Java EE Tools——>Generate Deployment Descriptor Stub.然后系统会在src/main/webapp/WEB_INF文件加下创建web.xml文件。错误解决！

或者在pom.xml中配置：

```xml
<build>
<plugins>
  <plugin>
    <groupId>org.apache.maven.plugins</groupId>
    <artifactId>maven-war-plugin</artifactId>
    <version>2.6</version>
    <configuration>
      <failOnMissingWebXml>false</failOnMissingWebXml>
    </configuration>
  </plugin>
</plugins>
</build>
```

