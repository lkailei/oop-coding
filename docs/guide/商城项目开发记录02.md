---
title: cloud-shop
autoGroup-5: 项目篇
---
# 基于cloud-shop开发记录问题

## 服务架构

### 技术选型

- Spring Cloud  Hoxton
- 消息中间件  RabbitMq
- 认证 Spring Security
- mysql tkmybaits
- 缓存 redis
- Elastic Search 全局搜索

## Spring Security

### Spring Security 自定义登录界面
```java
@EnableWebSecurity
public class SecurityConfig extends WebSecurityConfigurerAdapter {
    @Autowired
    private UserDetailsService userDetailsServiceImpl;

    @Autowired
    private AuthenticationSuccessHandler authenticationSuccessHandler;


    @Bean
    PasswordEncoder passwordEncoder() {
        return new BCryptPasswordEncoder();
    }
    // 注入数据源对象
    /**
     * 配置认证管理器
     *
     * @param auth
     * @throws Exception
     */
    @Override
    protected void configure(AuthenticationManagerBuilder auth) throws Exception {
        // 这个是内存中的比对
        //auth.inMemoryAuthentication().withUser("admin").password(passwordEncoder().encode("123456")).roles("admin");
        // 通过userDetailsServiceImpl进行认证
        auth.userDetailsService(userDetailsServiceImpl).passwordEncoder(passwordEncoder());
    }

    /**
     * configure(HttpSecurity)方法定义了哪些URL路径应该被保护，哪些不应该。具体来说，“/”和“/ home”路径被配置为不需要任何身份验证。所有其他路径必须经过身份验证。
     * 用来配置 HttpSecurity 。 HttpSecurity 用于构建一个安全过滤器链 SecurityFilterChain 。SecurityFilterChain 最终被注入核心过滤器
     * HttpSecurity的使用：
     *
     * @param http
     * @throws Exception
     */
    @Override
    protected void configure(HttpSecurity http) throws Exception {
        http.csrf().disable(); // 关闭CSrf的配置，但是默认是开启的CERF
        http.authorizeRequests()//开启登录配置
                // 设置哪些访问路径不需要访问权限，可以直接访问
                .antMatchers("/resources/**","/login.html","/logins.html","/css/**","/js/**","/img/**","/img/login/**","/img/index/**"
                ).permitAll()
                .anyRequest().authenticated()//表示剩余的其他接口，登录之后就能访问
                .and()
                .formLogin()
                //定义登录页面，未登录时，访问一个需要登录之后才能访问的接口，会自动跳转到该页面
                .loginPage("/login.html")
                .loginProcessingUrl("/admin/doLogin")
                .permitAll()
                // 定义登录成功的处理界面
                .successHandler(authenticationSuccessHandler)
                .permitAll();
        http.exceptionHandling().accessDeniedPage("/login.html");
        // 跳转到log
        http.logout().logoutUrl("/logout").logoutSuccessUrl("/login.html");
        /**
         * 同源策略
         * spring Security下，X-Frame-Options默认为DENY,非spring Security环境下，X-Frame-Options的默认大多也是DENY，
         * 这种情况下，浏览器拒绝当前页面加载任何Frame页面，设置含义如下：
         * • DENY：浏览器拒绝当前页面加载任何Frame页面
         * • SAMEORIGIN：frame页面的地址只能为同源域名下的页面
         * • ALLOW-FROM：origin为允许frame加载的页面地址
         */
        http.headers().frameOptions().sameOrigin();
    }

}
```
```java
@Configuration
@Slf4j
public class MyWebMvcConfigurerAdapter extends WebMvcConfigurationSupport  {



	@Override
	    public void addViewControllers( ViewControllerRegistry registry ) {
			registry.addRedirectViewController("/","/login.html");
			registry.addRedirectViewController("/main","/main.html");
	        super.addViewControllers( registry );
	    } 
	
	@Override
	protected void addResourceHandlers(ResourceHandlerRegistry registry) {
		// TODO Auto-generated method stub
			
		registry.addResourceHandler("/**")
         	.addResourceLocations("classpath:/static/");
		log.info("配置resources %s",registry.toString());
		super.addResourceHandlers(registry);
	}

	@Override
	protected void addInterceptors(InterceptorRegistry registry) {
		// TODO Auto-generated method stub
		super.addInterceptors(registry);
	}

	
}
```
### Spring Security 配置登录成功跳转的路径
```java
@Slf4j
@Service
public class AuthenticationSuccessHandlerImpl extends SavedRequestAwareAuthenticationSuccessHandler {

    @Autowired
    private LoginLogService loginLogService;

    @Override
    public void onAuthenticationSuccess(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Authentication authentication) throws IOException, ServletException {
        //登录后会调用
        log.info("记录日志");
        String loginName = authentication.getName();
        String ip = httpServletRequest.getRemoteAddr();

        LoginLog loginLog=new LoginLog();
        loginLog.setLoginName(loginName);//当前登录管理员
        loginLog.setLoginTime(new Date());//当前登录时间
        loginLog.setIp(ip);//远程客户端ip
        loginLog.setLocation(WebUtil.getCityByIP(ip)); //地区
        String agent = httpServletRequest.getHeader("user-agent");
        System.out.println("agent:"+agent);
        loginLog.setBrowserName(WebUtil.getBrowserName(agent));//浏览器名称
        loginLogService.add(loginLog);
        log.info("{}已经登录成功",loginName);
        // 这个加入会出现问题 405错误不支持post
//        httpServletRequest.getRequestDispatcher("/main.html").forward(httpServletRequest,httpServletResponse);
        RequestCache requestCache = new HttpSessionRequestCache();
        SavedRequest savedRequest =  requestCache.getRequest(httpServletRequest, httpServletResponse);

        if (savedRequest == null) {
            super.onAuthenticationSuccess(httpServletRequest, httpServletResponse, authentication);
            return;
        }
        //  使用saveRequest.getRedirectUrl会使得获取最后请求的资源的地址，而一般最后请求的资源地址是css之类的。
//        String targetUrl = savedRequest.getRedirectUrl();
//        logger.debug("Redirecting to DefaultSavedRequest Url: " + targetUrl);
        String targetUrl="/main.html";
        //  getRedirectStrategy() 允许在重定向到目标 URL 时覆盖行为
        getRedirectStrategy().sendRedirect(httpServletRequest, httpServletResponse, targetUrl);
    }
}

```

## RBAC模型
权限系统提的最多的就是 RBAC（Role-Based Access Control 基于角色的访问控 制）。
所谓角色，其实就是权限的集合，某个角色就是某几个权限的结合。其目的是为 了简化授权和鉴权的过程

企业开发中RBAC模型设计为7张表，其中4张为基本表3张为辅助表
- 用户表
- 角色表
- 权限(资源表)
- 菜单表
- 用户角色表
- 角色权限表
- 资源菜单表
[![RRPW36.png](https://z3.ax1x.com/2021/07/03/RRPW36.png)](https://imgtu.com/i/RRPW36)
## 订单操作

### Spring data-redis
1.连接池自动管理，提供了一个高度封装的redisTemplate

2.针对jedis客户端中大量api进行了归类封装,将同一类型操作封装为operation接口

    ValueOperations：简单K-V操作
    SetOperations：set类型数据操作
    ZSetOperations：zset类型数据操作
    HashOperations：针对map类型的数据操作
    ListOperations：针对list类型的数据操作

3.提供了对key的“bound”(绑定)便捷化操作API，可以通过bound封装指定的key，然后进行一系列的操作而无须“显式”的再次指定Key，即BoundKeyOperations：

    BoundValueOperations
    BoundSetOperations
    BoundListOperations
    BoundSetOperations
    BoundHashOperations

4.将事务操作封装，有容器控制。

5.针对数据的“序列化/反序列化”，提供了多种可选择策略(RedisSerializer)

- JdkSerializationRedisSerializer：POJO对象的存取场景，使用JDK本身序列化机制，将pojo类通过ObjectInputStream/ObjectOutputStream进行序列化操作，最终redis-server中将存储字节序列。是目前最常用的序列化策略。

- StringRedisSerializer：Key或者value为字符串的场景，根据指定的charset对数据的字节序列编码成string，是“new String(bytes, charset)”和“string.getBytes(charset)”的直接封装。是最轻量级和高效的策略。

- JacksonJsonRedisSerializer：jackson-json工具提供了javabean与json之间的转换能力，可以将pojo实例序列化成json格式存储在redis中，也可以将json格式的数据转换成pojo实例。因为jackson工具在序列化和反序列化时，需要明确指定Class类型，因此此策略封装起来稍微复杂。【需要jackson-mapper-asl工具支持】

- OxmSerializer：提供了将javabean与xml之间的转换能力，目前可用的三方支持包括jaxb，apache-xmlbeans；redis存储的数据将是xml工具。不过使用此策略，编程将会有些难度，而且效率最低；不建议使用。【需要spring-oxm模块的支持】

#### 实践
```xml
    <!-- redis-->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-starter-data-redis</artifactId>
    </dependency>
```
```java
@Autowired
private RedisTemplate redisTemplate;
// 放入redis
redisTemplate.boundHashOps(CacheKey.CART_LIST).put(username,cartList);
// 从redis取
List<Map<String, Object>>  cartList=(List<Map<String, Object>>) redisTemplate.boundHashOps(CacheKey.CART_LIST).get(username);

```
#### 缓存雪崩

目前电商首页以及热点数据都会去做缓存 ，一般缓存都是定时任务去刷新，或者是查不到之后去更新的，定时任务刷新就有一个问题。

当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，会给后端系统带来很大压 力。导致系统崩溃。

**如何避免?**

 1：在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个 key 只允许一个 线程查询数据和写缓存，其他线程等待。

 2：做二级缓存，A1 为原始缓存，A2 为拷贝缓存，A1 失效时，可以访问 A2，A1 缓存失效时间设置 为短期，A2 设置为长期 

 3：不同的 key，设置不同的过期时间，让缓存失效的时间点尽量均匀 
 4：使用缓存预热

#### 缓存穿透

 一般的缓存系统，都是按照 key 去缓存查询，如果不存在对应的 value，就应该去后端系统查找（比如  DB）。一些恶意的请求会故意查询不存在的 key,请求量很大，就会对后端系统造成很大的压力。这就叫  做缓存穿透。 

**如何避免?**

 1：对查询结果为空的情况也进行缓存，缓存时间设置短一点，或者该key 对应的数据 insert 了之后清 理缓存。 

 2：对一定不存在的 key 进行过滤。可以把所有的可能存在的 key 放到一个大的 Bitmap 中，查询时通过 该 bitmap 过滤。 

`缓存穿透`我会在接口层增加校验，比如用户鉴权校验，参数做校验，不合法的参数直接代码Return，比如：id 做基础校验，id <=0的直接拦截等。
 ```java
public int findPrice(Long id) { 
    //从缓存中查询
    Integer sku_price = (Integer)redisTemplate.boundHashOps("sku_price").get(id); 
    if(sku_price==null){ 
        //缓存中没有，从数据库查询 
        Sku sku = skuMapper.selectByPrimaryKey(id); 
        if(sku!=null){ 
            //如果数据库有此对象 
            sku_price = sku.getPrice(); 
            redisTemplate.boundHashOps("sku_price").put(id,sku_price); 
        }else{
            redisTemplate.boundHashOps("sku_price").put(id,0); 
        } 
    }
    return sku_price; 
}
 ```
 3：使用缓存预热的方式，直接从缓存中进行取数据，不必去数据库进行查询。


#### 缓存击穿

 缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力

**解决方案：**

1. 设置热点数据永远不过期。<br/>
2. 加互斥锁，互斥锁参考代码如下
3. 缓存预热方式

##### 使用布隆过滤器解决缓存击穿

`布隆过滤器（Bloom Filter）`这个也能很好的防止缓存穿透的发生，他的原理也很简单就是利用高效的数据结构和算法快速判断出你这个Key是否在数据库中存在，不存在你return就好了，存在你就去查了DB刷新KV再return。

`缓存击穿`的话，设置热点数据永远不过期。或者加上互斥锁就能搞定了

#### 缓存与数据库双写不一致

一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统不是严格要求 “缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：读请求和写请求串行化，串到一个内存队列里去。

串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况下多几倍的机器去支撑线上的一个请求。

Cache Aside Pattern

最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，先更新数据库，然后再删除缓存。

 

为什么是删除缓存，而不是更新缓存？

原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。

比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才能计算出缓存最新的值的。

**1、最初级的缓存不一致问题以及解决方案**

**问题：**

先修改数据库，再删除缓存，如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧数据，数据出现不一致。

**解决思路：**

　　先删除缓存，再修改数据库，如果删除缓存成功了修改数据库失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致，因为读的时候缓存没有，则读数据库中旧数据，然后更新到缓存中。

　　[![BoYXxH.md.png](https://s1.ax1x.com/2020/11/08/BoYXxH.md.png)](https://imgchr.com/i/BoYXxH)

其实还有以下解决方案：

1. 先删缓存，再更新数据库
2. 先更新数据库，再删缓存
3. 缓存延时双删，更新前先删除缓存，然后更新数据，再延时删除缓存
4. 监听MySQL binlog进行缓存更新

[可参考：缓存与数据库双写一致性最佳解决方案](https://www.jianshu.com/p/dc1e5091a0d8)

**2、并发下数据缓存不一致问题分析**

**问题**：

　　第一个请求数据发生变更，先删除了缓存，然后要去修改数据库，此时还没来得及去修改；

　　第二个请求过来去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中；

　　第三个请求读取缓存中的数据 (此时第一个请求已经完成了数据库修改的操作)。

　　完了，数据库和缓存中的数据不一样了。。。。

**问题分析：**

　　只有在对同一条数据并发读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的话，特别是读并发很低，每天访问量就1万次，那么很少的情况下，会出现刚才描述的那种不一致的场景;但如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就可能会出现上述的数据库+缓存不一致的情况。

**解决思路**

　　数据库的缓存更新与读取操作进行串行化，一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。

1. 首先我们的项目里维护一组线程池和内存队列。
2. 更新数据的时候，根据数据的唯一标识将请求路由到一个jvm队列中，去更新数据库,然后请求结束。
3. 读取数据的时候，先查缓存，如果发现数据不在缓存中，那么将根据唯一标识路由之后，也发送同一个jvm内部的队列中，重新读取数据库后更新缓存,最后请求结束。

[![BoYLGD.md.png](https://s1.ax1x.com/2020/11/08/BoYLGD.md.png)　　

这里有一个需要优化的点，比如一个队列中，连续存在多个更新缓存请求串在一起是没意义的，这样重复的查询数据库并更新缓存的操作应该优化：如果发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接让后面的读请求阻塞个200ms左右(这里只是举个例子，实际值可以根据服务的响应时间和机器的处理能力来计算)，然后再次查询缓存，如果缓存没有值就查数据库，拿到结果后不用更新缓存，直接返回给页面即可。

[参考：缓存与数据库双写不一致](
### CAP定理&Base理论
#### CAP定理
C:Consistency 一致性

A:Availability 可用性

P:Partition tolerance 分区容错性

要么AP，要么CP

#### Base理论

全称：Basically Available(基本可用)，Soft state（软状态）,和 Eventually consistent（最终一致性）三个短语的缩写，来自 ebay 的架构师提出。BASE 理论是对 CAP 中一致性和可用性权衡的结果，其来源于对大型互联网分布式实践的总结，是基于 CAP 定理逐步演化而来的。

其核心思想是： 既是无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务 特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。

- Basically Available(基本可用) 
    什么是基本可用呢？假设系统，出现了不可预知的故障，但还是能用，相比较正常的系 统而言： 
    1. 响应时间上的损失：正常情况下的搜索引擎 0.5 秒即返回给用户结果，而基本可用的 搜索引擎可以在 1 秒作用返回结果。
    2. 功能上的损失：在一个电商网站上，正常情况下，用户可以顺利完成每一笔订单，但 是到了大促期间，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级 页面。

- Soft state（软状态） 什么是软状态呢？相对于原子性而言，要求多个节点的数据副本都是一致的，这是一种 “硬状态”。 
    软状态指的是：允许系统中的数据存在中间状态，并认为该状态不影响系统的整体可用 性，即允许系统在多个不同节点的数据副本存在数据延时。

- Eventually consistent（最终一致性） 
    系统能够保证在没有其他新的更新操作的情况下，数据最终一定能够达到一致的状态， 因此所有客户端对系统的数据访问最终都能够获取到最新的值。

### 分布式事务
分布式事务的目的就是保证数据一致性。
#### 基于XA协议的两阶段提交

[![R26vIf.png](https://z3.ax1x.com/2021/07/03/R26vIf.png)](https://imgtu.com/i/R26vIf)
可知XA规范中分布式事务有AP，RM，TM组成： 

    其中应用程序(Application Program ，简称AP)：AP定义事务边界（定义事务开始和结 束）并访问事务边界内的资源。 
       
    资源管理器(Resource Manager，简称RM)：Rm管理计算机共享的资源，许多软件都可 以去访问这些资源，资源包含比如数据库、文件系统、打印机服务器等。
    事务管理器(Transaction Manager ，简称TM)：负责管理全局事务，分配事务唯一标 识，监控事务的执行进度，并负责事务的提交、回滚、失败恢复等。 
    二阶段协议: 
     第一阶段TM要求所有的RM准备提交对应的事务分支，询问RM是否有能力保证成功的提 交事务分支，RM根据自己的情况，如果判断自己进行的工作可以被提交，那就就对工作 内容进行持久化，并给TM回执OK；否者给TM的回执NO。RM在发送了否定答复并回滚 了已经的工作后，就可以丢弃这个事务分支信息了。
     第二阶段TM根据阶段1各个RM prepare的结果，决定是提交还是回滚事务。如果所有的 RM都prepare成功，那么TM通知所有的RM进行提交；如果有RM prepare回执NO的 话，则TM通知所有RM回滚自己的事务分支。 也就是TM与RM之间是通过两阶段提交协议进行交互的. 
     优点： 尽量保证了数据的强一致，适合对数据强一致要求很高的关键领域。（其实也不 能100%保证强一致） 
     缺点： 实现复杂，牺牲了可用性，对性能影响较大，不适合高并发高性能场景。

#### TCC补偿机制
TCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应 的确认和补偿（撤销）操作。它分为三个阶段： 

Try 阶段主要是对业务系统做检测及资源预留 Confirm 阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行

Confirm 阶段时，默认 Confirm阶段是不会出错的。即：只要Try成功，Confirm一定成功。 

Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源 释放
[![R2cmJU.png](https://z3.ax1x.com/2021/07/03/R2cmJU.png)](https://imgtu.com/i/R2cmJU)

优点： 相比两阶段提交，可用性比较强 

缺点： 数据的一致性要差一些。TCC属于应用层的一种补偿方式，所以需要程序员在实 现的时候多写很多补偿的代码，在一些场景中，一些业务流程可能用TCC不太好定义及处 理。

####  最终消息一致性
基本思路就是： 消息生产方，需要额外建一个消息表，并记录消息发送状态。

消息表和业务数据要在一 个事务里提交，也就是说他们要在一个数据库里面。然后消息会经过MQ发送到消息的消 费方。如果消息发送失败，会进行重试发送。

 消息消费方，需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成 功，表明已经处理成功了，如果处理失败，那么就会重试执行。如果是业务上面的失 败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。 

 生产方和消费方定时扫描本地消息表，把还没处理完成的消息或者失败的消息再发送一 遍。如果有靠谱的自动对账补账逻辑，这种方案还是非常实用的。

 [![R2caSe.png](https://z3.ax1x.com/2021/07/03/R2caSe.png)](https://imgtu.com/i/R2caSe)

 优点： 一种非常经典的实现，避免了分布式事务，实现了最终一致性。 

 缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处 理

 #### 扣减库存实现消息最终一致性
 在下订单时我们先进行库存减少，当创建订单有异常时我们发送库存数量回滚操作
 ```java
try{} catch (Exception e) {
            e.printStackTrace();
            // 分布式事务
            //发送回滚消息
            // convertAndSend:使用此方法，交换机会马上把所有的信息都交给所有的消费者，消费者再自行处理，不会因为消费者处理慢而阻塞线程。
            // convertSendAndReceive()可以同步消费者。使用此方法，当确认了所有的消费者都接收成功之后，才触发另一个convertSendAndReceive(…)，也就是才会接收下一条消息。RPC调用方式。
            rabbitTemplate.convertAndSend("skuback","queue.skuback", JSON.toJSONString(orderItemList));
            throw new RuntimeException("创建订单失败");
        }
 ```
在goods服务中进行监听这个消息，读取rabbitmq传递的信息，然后进行对库存进行回滚操作
```java
// rabbitMq客户端进行监听这个消息
 /**
     * 消费消息采用消息队列监听机制
     * @RabbitHandler - 代表当前方法是监听对列的方法，就是队列状态放生变化后，执行的消费消息的方法
     * @param message
     */
    @RabbitHandler
    @RabbitListener(
            bindings = @QueueBinding(
                    value=@Queue(value = "queue.skuback"),
                    exchange=@Exchange(value = "skuback"),
                    key = "qqq")) // 监听的队列
    public void process(Message message){
        try {
            log.info("监听队列queue.skuback....");
            log.info(message.getBody().toString());
            //提取消息
            String jsonString = new String(message.getBody());
            List<OrderItem> orderItemList = JSON.parseArray(jsonString, OrderItem.class);
            // 记录回滚操作操作
            stockBackService.addList(orderItemList);
        } catch (Exception e) {
            e.printStackTrace();
            //记录日志，之后人工干预
        }
    }
```
 ### 购物车功能逻辑实现
 [![R2guAP.png](https://z3.ax1x.com/2021/07/03/R2guAP.png)](https://imgtu.com/i/R2guAP)
 ### 订单生成逻辑 
[![R2gYBn.png](https://z3.ax1x.com/2021/07/03/R2gYBn.png)](https://imgtu.com/i/R2gYBn) 
 ### 订单超时关闭
 #### Corn表达式
 Cron表达式是一个字符串，字符串以5或6个空格隔开，分开工6或7个域，每一个域代表 一个含义,

 Cron有如下两种语法 格式： Seconds Minutes Hours DayofMonth Month DayofWeek Year 或 Seconds Minutes Hours DayofMonth Month DayofWeek 
 注意：SpringTask不支持第一种格式，也就是说只能写6个域！ 

 每一个域可出现的字符如下：

    代码Seconds:可出现,- * / 四个字符，有效范围为0-59的整数 
    Minutes:可出现,- * / 四个字符，有效范围为0-59的整数 
    Hours:可出现,- * / 四个字符，有效范围为0-23的整数 
    DayofMonth:可出现,- * / ? L W C八个字符，有效范围为1-31的整数 
    Month:可出现,- * / 四个字符，有效范围为1-12的整数或JAN-DEc
    ayofWeek:可出现,- * / ? L C #四个字符，有效范围为1-7的整数或SUN-SAT两个范围。 1表示星期天，2表示星期一， 依次类推 
    Year:可出现,- * / 四个字符，有效范围为1970-2099年 每一个域都使用数字，但还可以出现如下特殊字符，它们的含义是：
     
    (1) *：表示匹配该域的任意值，假如在Minutes域使用*,即表示每分钟都会触发事件。
    (2) ?: 只能用在DayofMonth和DayofWeek两个域。它也匹配域的任意值，但实际不会。 因为DayofMonth和DayofWeek会相互影响。 例如想在每月的20日触发调度，不管20日到底是星期几，则只能使用如下写法： 13 13 15 20 * ?,其中最后一位只能用？，而不能使用*， 如果使用*表示不管星期几都会触发，实际上并不是这样。 
    (3)-:表示范围，例如在Minutes域使用5-20，表示从5分到20分钟每分钟触发一次 
    (4)/：表示起始时间开始触发，然后每隔固定时间触发一次，例如在Minutes域使用5/20, 则意味着5分钟触发一次，而25，45等分别触发一次. 
    (5),:表示列出枚举值值。例如：在Minutes域使用5,20，则意味着在5和20分每分钟触发 一次。 
    (6)L:表示最后，只能出现在DayofWeek和DayofMonth域，如果在DayofWeek域使用5L, 意味着在最后的一个星期四触发。 
    (7)W:表示有效工作日(周一到周五),只能出现在DayofMonth域，系统将在离指定日期的 最近的有效工作日触发事件。 例如：在DayofMonth使用5W，如果5日是星期六，则将在最近的工作日：星期五，即4 日触发。如果5日是星期天，则在6日触发； 如果5日在星期一到星期五中的一天，则就在5日触发。另外一点，W的最近寻找不会跨 过月份 
    (8)LW:这两个字符可以连用，表示在某个月最后一个工作日，即最后一个星期五。 
    (9)#:用于确定每个月第几个星期几，只能出现在DayofMonth域。例如在4#2，表示某月 的第二个星期三。
 #### 订单超时关闭
 根据设置的订单超时时间进行定时任务处理超时订单进行关闭。
 ```java
    /**
     * 订单超时处理 没两分钟处理一次请求，将60分钟前未支付的订单进行关闭
     */
    @Scheduled(cron = "0 0/2 * * *  ?")
    public void orderTimeOutLogic(){
        orderService.orderTimeOutLogic();
    }
    /**
     * 订单超时未付款。关闭订单
     */
    @Override
    public void orderTimeOutLogic() {
        //订单超时未付款 自动关闭
        // 查询超时时间
        OrderConfig orderConfig = orderConfigMapper.selectByPrimaryKey(1);
        Integer orderTimeout = orderConfig.getOrderTimeout();
        //超时时间 （分） 60
        LocalDateTime localDateTime = LocalDateTime.now().minusMinutes(orderTimeout);
        //得到超时的时间点 //设置查询条件
        Example example = new Example(Order.class);
        Example.Criteria criteria = example.createCriteria();
        criteria.andLessThan("createTime", localDateTime);
        //创建时间小于超时 时间
        criteria.andEqualTo("orderStatus", "0");
        //未付款的
        criteria.andEqualTo("isDelete", "0");
        //未删除的 //查询超时订单
        List<Order> orders = orderMapper.selectByExample(example);
        for (Order order : orders) {
            //记录订单变动日志
            OrderLog orderLog = new OrderLog();
            orderLog.setOperater("system");
            // 系统
            orderLog.setOperateTime(new Date());
            //当前日期
            orderLog.setOrderStatus("4");
            orderLog.setPayStatus(order.getPayStatus());
            orderLog.setConsignStatus(order.getConsignStatus());
            orderLog.setRemarks("超时订单，系统自动关闭");
            orderLog.setOrderId(order.getId());
            orderLogMapper.insert(orderLog);
            //更改订单状态
            order.setOrderStatus("4");
            //关闭日期
            order.setCloseTime(new Date());
            orderMapper.updateByPrimaryKeySelective(order);
        }
    }
 ```
## RabbitMQ使用

centos下rabbitMq启动出现问题：

https://blog.csdn.net/qq_37256896/article/details/100832341

RabbitMq不能连接： 将连接 端口从15672改为 5672
```bash
2021-05-26 11:11:26.717  INFO 11676 --- [           main] o.s.a.r.c.CachingConnectionFactory       : Attempting to connect to: [192.168.230.130:15672]
2021-05-26 11:11:31.732  INFO 11676 --- [           main] o.s.a.r.l.SimpleMessageListenerContainer : Broker not available; cannot force queue declarations during start: java.util.concurrent.TimeoutException
2021-05-26 11:11:31.735 ERROR 11676 --- [8.230.130:15672] c.r.c.impl.ForgivingExceptionHandler     : An unexpected connection driver error occured

java.net.SocketException: Socket Closed
	at java.net.SocketInputStream.socketRead0(Native Method) ~[na:1.8.0_91]
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116) ~[na:1.8.0_91]
	at java.net.SocketInputStream.read(SocketInputStream.java:170) ~[na:1.8.0_91]
```

RabbitMq接收消息报错：
```bash
2021-05-26 11:27:14.842  WARN 2580 --- [ntContainer#0-1] s.a.r.l.ConditionalRejectingErrorHandler : c.

org.springframework.amqp.rabbit.support.ListenerExecutionFailedException: Listener threw exception
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.wrapToListenerExecutionFailedExceptionIfNeeded(AbstractMessageListenerContainer.java:1722) ~[spring-rabbit-2.2.12.RELEASE.jar:2.2.12.RELEASE]
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doInvokeListener(AbstractMessageListenerContainer.java:1612) ~[spring-rabbit-2.2.12.RELEASE.jar:2.2.12.RELEASE]
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.actualInvokeListener(AbstractMessageListenerContainer.java:1527) ~[spring-rabbit-2.2.12.RELEASE.jar:2.2.12.RELEASE]
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.invokeListener(AbstractMessageListenerContainer.java:1515) ~[spring-rabbit-2.2.12.RELEASE.jar:2.2.12.RELEASE]
	at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.doExecuteListener(AbstractMessageListenerContainer.java:1506) ~[spring-rabbit-2.2.12.RELEASE.jar:2.2.12.RELEASE]
....
....
```
原本配置注解@RabbitListener 是在类头上的需要改到方法名称上面直接放到方法
```java
/**
 * user:kay三石
 * time: 22:11
 * desc:
 * RabbitListener :必须配合@RabbitHandler才能实现rabbit消息消费能力，一个类可以有多个方法，但是仅有一个方法注解@RabbitHandler。
 * @RabbitListener -  代表当前类型是一个rabbitmq的监听器。
 *       bindings:绑定队列
 *   @QueueBinding  - @RabbitListener.bindings属性的类型。绑定一个队列。
 *        value:绑定队列， Queue类型。
 *        exchange:配置交换器， Exchange类型。
 *        key:路由键，字符串类型。
 *
 *   @Queue - 队列。
 *        value:队列名称
 *        autoDelete:是否是一个临时队列。
 *           true ：当所有的consumer关闭后，自动删除queue。
 *           false：当任意一个consumer启动并创建queue后，如果queue中有消息未消费，无论是否有consumer继续执行，都保存queue。
 *
 *   @Exchange - 交换器
 *        value:为交换器起个名称
 *        type:指定具体的交换器类型
 **/
@Component
@Slf4j
public class StockBackMessageConsumer {

    @Autowired
    private StockBackService stockBackService;

    /**
     * 消费消息采用消息队列监听机制
     * @RabbitHandler - 代表当前方法是监听对列的方法，就是队列状态放生变化后，执行的消费消息的方法
     * @param message
     */
    @RabbitHandler
    @RabbitListener(
            bindings = @QueueBinding(
                    value=@Queue(value = "queue.skuback"),
                    exchange=@Exchange(value = "skuback"),
                    key = "qqq")) // 监听的队列
    public void process(Message message){
        try {
            log.info(message.getBody().toString());
            //提取消息
            String jsonString = new String(message.getBody());
            List<OrderItem> orderItemList = JSON.parseArray(jsonString, OrderItem.class);
            stockBackService.addList(orderItemList);
        } catch (Exception e) {
            e.printStackTrace();
            //记录日志，之后人工干预
        }
    }
}
```
## ElasticSearch

elasticsearch 报错：
elasticsearch 6.5.3 :Found interface org.elasticsearch.common.bytes.BytesReference, but class was
修正如下：和spring boot parent中的一致要：

		<dependency>
			<groupId>org.elasticsearch.client</groupId>
			<artifactId>elasticsearch-rest-high-level-client</artifactId>
			<version>7.6.2</version>
		</dependency>

elasticsearch的操作在kibana中
```
# 创建索引结构
PUT sku 
{ 
  "mappings":{ 
    "doc":{ 
      "properties":{
        "name":{
          "type":"text", "analyzer":"ik_smart" 
          
        },
        "price":{
          "type":"integer" 
          
        },
        "image":{
          "type":"text" 
          
        },
        "createTime":{ 
          "type":"date" 
        },
        "spuId":{
          "type":"text" 
          
        },
        "categoryName":{ 
          "type":"keyword" 
          
        },
        "brandName":{
          "type":"keyword" 
          
        },
        "spec":{ 
          "type":"object"
        },
        "saleNum":{ 
          "type":"integer"
        },
        "commentNum":{
          "type":"integer" 
          
        } 
        
      } 
      
    } 
  } 
}
# 删除索引库


# 插入文档
POST sku/doc 
{ 
  "name":"小米手机",
  "price":1000,
  "spuId":"101",
  "createTime": "2019‐03‐01",
  "categoryName":"手机",
  "brandName":"小米",
  "saleNum":10102, 
  "commentNum":1331, 
  "spec":{ 
    "网络制式":"移动4G", 
    "屏幕尺寸":"4.5"
    } 
}
# 查询
GET sku/_search

# 新增文档同时指定id
PUT sku/doc/1 
{
  "name":"小米电视", 
  "price":1000, 
  "spuId":1010101011,
  "createTime":"2019‐03‐01", 
  "categoryName":"电视",
  "brandName":"小米", 
  "saleNum":10102, 
  "commentNum":1331, 
  "spec":{ 
    "网络制式":"移动4G",
    "屏幕尺寸":"4.5"
    } 
}

# 查询所有
GET /sku/_search 
{ 
  "query":{
    "match_all": {} 
  } 
}

# 匹配查询
GET /sku/doc/_search 
{ 
  "query": {
    "match":{
      "name":"手机"
    } 
  } 
}

# 词条匹配
GET /sku/_search
{
    "query":{
        "term":{
            "price":1000
        }
    }
}

#多词条匹配
GET /sku/_search
{
    "query":{
        "term":{
            "price":[1000,2000,3000]
        }
    }
}

# 过滤
#过滤是针对搜索的结果进行过滤，过滤器主要判断的是文档是否匹配，不去计算和 判断文档的匹配度得分，所以过滤器性能比查询要高，且方便缓存，推荐尽量使用过滤 器去实现查询或者过滤器和查询共同使用
GET /sku/_search
{
    "query":{
        "bool":{
            "filter":[
                {
                    "match":{
                        "brandName":"小米"
                    }
                }
            ]
        }
    }
}

#分组查询  一次查询两种分组统计结果
GET sku/_search
{
    "size":0,
    "aggs":{
        "sku_category":{
            "terms":{
                "field":"categoryName"
            }
        },
        "sku_brand":{
            "terms":{
                "field":"brandName"
            }
        }
    }
}
```
发送请求查询时报错：
```bash
ElasticsearchStatusException[Elasticsearch exception [type=illegal_argument_exception, reason=request [/sku/doc/_search] contains unrecognized parameter: [ccs_minimize_roundtrips]]]
	at org.elasticsearch.rest.BytesRestResponse.errorFromXContent(BytesRestResponse.java:177)
	...
	...
	org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.lang.Thread.run(Thread.java:745)
	Suppressed: org.elasticsearch.client.ResponseException: method [POST], host [http://192.168.230.130:9200], URI [/sku/doc/_search?pre_filter_shard_size=128&typed_keys=true&max_concurrent_shard_requests=5&ignore_unavailable=false&expand_wildcards=open&allow_no_indices=true&ignore_throttled=true&search_type=query_then_fetch&batched_reduce_size=512&ccs_minimize_roundtrips=true], status line [HTTP/1.1 400 Bad Request]
{"error":{"root_cause":[{"type":"illegal_argument_exception","reason":"request [/sku/doc/_search] contains unrecognized parameter: [ccs_minimize_roundtrips]"}],"type":"illegal_argument_exception","reason":"request [/sku/doc/_search] contains unrecognized parameter: [ccs_minimize_roundtrips]"},"status":400}
		at org.elasticsearch.client.RestClient.convertResponse(RestClient.java:283)
		at org.elasticsearch.client.RestClient.performRequest(RestClient.java:261)
		at org.elasticsearch.client.RestClient.performRequest(RestClient.java:235)
		at org.elasticsearch.client.RestHighLevelClient.internalPerformRequest(RestHighLevelClient.java:1514)
		... 59 more
调用了公共异常处理类
2021-05-26 22:08:56.712  INFO 27728 --- [trap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration
2021-05-26 22:13:59.596  INFO 27728 --- [trap-executor-0] c.n.d.s.r.aws.ConfigClusterResolver      : Resolving eureka endpoints via configuration

```
这个问题可以在官网找打这个参数。官方说：
ccs_minimize_roundtrips
(Optional, Boolean) If true, network round-trips between the coordinating node and the remote clusters are minimized when executing cross-cluster search (CCS) requests. See How cross-cluster search handles network delays. Defaults to true.
(可选，Boolean)如果为true，则在执行跨集群搜索(cross-cluster search, CCS)请求时，协调节点与远程集群之间的网络往返次数最小化。请参阅跨集群搜索如何处理网络延迟。默认值为true。

更换es 版本和springboot中包含的版本一致 

 ## 秒杀

秒杀商品通常有两种限制：**库存限制**，**时间限制**

秒杀技术实现核心思想是运用缓存减少数据库瞬间的访问压力！读取商品详细信息时运用缓存，当用户点击抢购时减
少缓存中的库存数量，当库存数为0时或活动期结束时，同步到数据库。 产生的秒杀预订单也不会立刻写到数据库
中，而是先写到缓存，当用户付款成功后再写入数据库




### 多线程下单(用户抢单)：
下订单这里，我们一般采用多线程下单，但多线程中我们又需要保证用户抢单的公平性，也就是先抢先下单。我们可
以这样实现，用户进入秒杀抢单，如果用户复合抢单资格，只需要记录用户抢单数据，存入队列，多线程从队列中进
行消费即可，存入队列采用左压，多线程下单采用右取的方式。
**java异步处理配置项**
```java
@Configuration
@EnableAsync // 表示可以进入异步处理
public class ThreadConfig implements AsyncConfigurer {
    /**
     * 配置线程池
     * @return
     */
    @Override
    public Executor getAsyncExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        // 初始化线程数量
        executor.setCorePoolSize(8);
        // 最大线程数量
        executor.setMaxPoolSize(1000);
        // 最大队列数量
        executor.setQueueCapacity(500);
        // 线程最大空闲时间
        executor.setKeepAliveSeconds(30000);
        // 拒绝测略，线程池中的线程使用完毕后采取的拒绝策略
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        executor.initialize();
        return executor;
    }

    @Override
    public AsyncUncaughtExceptionHandler getAsyncUncaughtExceptionHandler() {
        return null;
    }
}
```
**多线程异步处理**
```java
 @Async
    public void createOrder() {
        try {
            Thread.sleep(1000);
            // 从redis队列中进行查询 左进右出，获取订单
            SeckillStatus seckillStatus = (SeckillStatus) redisTemplate.boundListOps("SeckillOrderQueueList").rightPop();

            if(seckillStatus!=null){
                // 超卖控制,获取所有的id
                Object sgoods = redisTemplate.boundListOps("SeckillGoodsIdCountList_" + seckillStatus.getGoodsId()).rightPop();
                if (sgoods==null){
                    // 清理当前排队的信息
                    clearQueue(seckillStatus);
                    return;
                }
                // 获取数据
                String username=seckillStatus.getUsername();
                String time=seckillStatus.getTime();
                Long id = seckillStatus.getGoodsId();

                //查询商品详情
                SeckillGoods goods = (SeckillGoods) redisTemplate.boundHashOps("SeckillGoods_" + time).get(id);

                if (goods != null && goods.getStockCount() > 0) {
                    //创建订单
                    SeckillOrder seckillOrder = new SeckillOrder();
                    seckillOrder.setId(idWorker.nextId());
                    seckillOrder.setSeckillId(id);
                    seckillOrder.setMoney(goods.getCostPrice());
                    seckillOrder.setUserId(username);
                    seckillOrder.setSellerId(goods.getSellerId());
                    seckillOrder.setCreateTime(new Date());
                    seckillOrder.setStatus("0");
                    redisTemplate.boundHashOps("SeckillOrder").put(username, seckillOrder);

                    //库存削减并发会出现问题
                    // goods.setStockCount(goods.getStockCount() - 1);
                    //改用使用redis方式,存入redis时需要把商品数量也存入redis,这边直接使用redis中的：
                    Long seckillGoodsCount = redisTemplate.boundHashOps("SeckillGoodsCount").increment(id, -1);// 商品数量递减
                    goods.setStockCount(seckillGoodsCount.intValue());

                    //商品库存=0->将数据同步到MySQL，并清理Redis缓存
//                  if (goods.getStockCount() <= 0) { 并发炒作有问题
                    if (seckillGoodsCount<=0){
                        seckillGoodsMapper.updateByPrimaryKeySelective(goods);
                        //清理Redis缓存。没有库存，清空Redis缓存中该商品
                        redisTemplate.boundHashOps("SeckillGoods_" + time).delete(id);
                    } else {
                        //如果有库存，将数据同步到Redis
                        redisTemplate.boundHashOps("SeckillGoods_" + time).put(id, goods);
                    }
                    // 变更抢单状态
                    seckillStatus.setOrderId(seckillOrder.getId());
                    seckillStatus.setMoney(seckillOrder.getMoney().floatValue());
                    seckillStatus.setStatus(2); // 抢单成功，待支付。前端只需要查询这个状态
                    redisTemplate.boundHashOps("UserQueueStatus").put(username,seckillStatus);
                }
                // 发送MQ消息
                sendDelayMessage(seckillStatus);

            }

        } catch (InterruptedException e) {
            e.printStackTrace();
        }

    }
```
### 排队下单
用户每次下单的时候，我们可以创建一个队列进行排队，然后采用多线程的方式创建订单，排队我们可以采用Redis
的队列实现。 排队信息中需要有用户抢单的商品信息，主要包含商品ID，商品抢购时间段，用户登录名。我们可以
设计个javabean：
```java
// 创建一个队列
SeckillStatus seckillStatus = new SeckillStatus(username,new Date(),1,id,time);
// 将队列传入到redis  排队抢单
// 用list模拟对列先进先出
redisTemplate.boundListOps("SeckillOrderQueueList").leftPush(seckillStatus);

```
多线程抢单时：
```java
// 从redis队列中进行查询 左进右出，获取订单
SeckillStatus seckillStatus = (SeckillStatus) redisTemplate.boundListOps("SeckillOrderQueueList").rightPop();

```

### 下单状态
每过1秒钟查询一次下单状态,多线程下单的时候，需要修改抢单状态，支付的时候，清理抢单状态。
用户每次点击抢购的时候，如果排队成功，则将用户抢购状态存储到Redis中，多线程抢单的时候，如果抢单成功，
则更新抢单状态
```java
 // 将抢单状态存入到Redis中
 redisTemplate.boundHashOps("UserQueueStatus").put(username,seckillStatus);
```
多线程抢单时：
```java
// 变更抢单状态
seckillStatus.setOrderId(seckillOrder.getId());
seckillStatus.setMoney(seckillOrder.getMoney().floatValue());
seckillStatus.setStatus(2); // 抢单成功，待支付。前端只需要查询这个状态
redisTemplate.boundHashOps("UserQueueStatus").put(username,seckillStatus);
```

### 防止秒杀重复排队

用户每次抢单的时候，一旦排队，我们设置一个自增值，让该值的初始值为1，每次进入抢单的时候，对它进行递
增，如果值>1，则表明已经排队,不允许重复排队,如果重复排队，则对外抛出异常，并抛出异常信息100表示已经正
在排队
```java

// 重复抢单数据处理
        // redis有自增特性
        // incr(key,value) 让指定的key自增value ->返回一个自增的值，单线程操作
        // A 第一次抢单 : incr(username,1)->1
        //   第二次抢单 : incr(username,1)->2
        //  利用自增，如果用户多次提交或者多次排队。则递增值》1
        Long userQueueCount = redisTemplate.boundHashOps("UserQueueCount").increment(username, 1);

        if(userQueueCount>1){
            // 错误状态码 100 :重复排队
            throw  new RuntimeException("100");
        }
```
 ### 超卖：
 指的是多人对同一商品抢购，如果只剩下一个，则都会判断有库存，此时会导致超卖现象产生，也就是
 一个商品下了多个订单。

 解决超卖问题，可以利用Redis队列实现，给每件商品创建一个独立的商品个数队列，例如：A商品有2个，A商品的
 ID为1001，则可以创建一个队列,key=SeckillGoodsCountList_1001,往该队列中塞2次该商品ID。
 每次给用户下单的时候，先从队列中取数据，如果能取到数据，则表明有库存，如果取不到，则表明没有库存，这样
 就可以防止超卖问题产生了。
 在我们队Redis进行操作的时候，很多时候，都是先将数据查询出来，在内存中修改，然后存入到Redis，在并发场
 景，会出现数据错乱问题，为了控制数量准确，我们单独将商品数量整一个自增键，自增键是线程安全的，所以不担
 心并发场景的问题。

 **在存放商品信息到redis中就进行对数量进行队列封装**
```java
    //3.将秒杀商品存入到Redis缓存
    for (SeckillGoods seckillGood : seckillGoods) {
        redisTemplate.boundHashOps("SeckillGoods_"+DateUtil.date2Str(startTime)).put(seckillGood.getId(),seckillGood);
        // 商品数据队列存储，防止高并发超卖
        //商品数据队列存储,防止高并发超卖
        Long[] ids = pushIds(seckillGood.getStockCount(), seckillGood.getId());
        // 包所有的商品id push到对列中,商品的数量和商品存起来
        // 转换为队列的列表，就是当前商品的 库存长度的 id数组 [id,id,id]将
        redisTemplate.boundListOps("SeckillGoodsIdCountList_"+seckillGood.getId()).leftPushAll(ids);
        // 商品总数自增计数器，为了解决库存问题
        redisTemplate.boundHashOps("SeckillGoodsCount").increment(seckillGood.getId(),seckillGood.getStockCount());
    }
    /**
     * 将商品Id存入到数组中
     * @param stockCount 商品id
     * @param id 商品自增id
     * @return
     */
    private Long[] pushIds(Integer stockCount, Long id) {
        Long[] ids = new Long[stockCount];
        for(int i=0;i<ids.length;i++){
            ids[i]=id;
        }
        return ids;
    }
```
**多线程下单时进行控制**
修改多线程下单方法，分别修改数量控制，以及售罄后用户抢单排队信息的清理
```java
    // 超卖控制,获取所有的id
    Object sgoods = redisTemplate.boundListOps("SeckillGoodsIdCountList_" + seckillStatus.getGoodsId()).rightPop();
    if (sgoods==null){
        // 清理当前排队的信息
        clearQueue(seckillStatus);
        return;
    }
    // 修改库存保证数据一致性
     //改用使用redis方式,存入redis时需要把商品数量也存入redis,这边直接使用redis中的：
    Long seckillGoodsCount = redisTemplate.boundHashOps("SeckillGoodsCount").increment(id, -1);// 商品数量递减
    goods.setStockCount(seckillGoodsCount.intValue());
    
    //商品库存=0->将数据同步到MySQL，并清理Redis缓存
    //                  if (goods.getStockCount() <= 0) { 并发炒作有问题
    if (seckillGoodsCount<=0){
        seckillGoodsMapper.updateByPrimaryKeySelective(goods);
        //清理Redis缓存。没有库存，清空Redis缓存中该商品
        redisTemplate.boundHashOps("SeckillGoods_" + time).delete(id);
    } else {
        //如果有库存，将数据同步到Redis
        redisTemplate.boundHashOps("SeckillGoods_" + time).put(id, goods);
    }` 
```

 ### 订单超时问题
 #### 问题分享
 用户每次下单后，不一定会立即支付，甚至有可能不支付，那么此时我们需要删除用户下的订单，并回滚库存。这里
 我们可以采用MQ的延时消息实现，每次用户下单的时候，如果订单创建成功，则立即发送一个延时消息到MQ中，
 等待消息被消费的时候，先检查对应订单是否下单支付成功，如果支付成功，会在MySQL中生成一个订单，如果
 MySQL中没有支付，则Redis中还有该订单信息的存在，需要删除该订单信息以及用户排队信息，并恢复库存。

 #### 解决方案：
 RabbitMQ延时对列：
 RabbitMQ并没有直接实现延时队列，但是可以利用RabbitMQ两个属性实现延时队列特性：

 - x-message-ttl：消息过期时间（Time To Live，TTL），超过过期时间之后即变为死信（Dead-letter），不会再
 被消费者消费。

     设置TTL有两种方式：
     （1）创建队列时指定x-message-ttl，此时整个队列具有统一过期时间；
     （2）发送消息为每个消息设置expiration，此时消息之间过期时间不同。
      注意：如果两者都设置，过期时间取两者最小。
 - x-dead-letter-exchange：过期消息路由转发，当消息达到过期时间由该exchange按照配置的x-dead-letterrouting-key转发到指定队列，最后被消费者消费。

**多线程抢单中**
```java
// 延时信息发送
 // 向rabbitMq发送消息
    private void sendDelayMessage(SeckillStatus seckillStatus) {
        rabbitTemplate.convertAndSend( "exchange.delay.order.begin", "delay",
                JSONObject.toJSONString(seckillStatus), new MessagePostProcessor() {
            @Override
            public Message postProcessMessage(Message message) throws AmqpException {
                //消息有效期30分钟
                // message.getMessageProperties().setExpiration(String.valueOf(1800000));
                message.getMessageProperties().setExpiration(String.valueOf(10000));
                return message;
            } });
    }

```
**rabbitMq进行监听,进行回滚操作**
```java
/**
 * user:kay三石
 * time: 22:37
 * desc:
 **/
@Component
@Slf4j
public class OrderMessageListener {
    @Autowired
    private RedisTemplate redisTemplate;

    @Autowired
    private WeixinPayService weixinPayService;

    @Autowired
    private SeckillGoodsMapper seckillGoodsMapper;


    /**
     * 消费消息采用消息队列监听机制
     * @RabbitHandler - 代表当前方法是监听对列的方法，就是队列状态放生变化后，执行的消费消息的方法
     * @param message
     */
    @RabbitHandler
    @RabbitListener(
            bindings = @QueueBinding(
                    value=@Queue(value = "queue.delay.order.begin"),
                    exchange=@Exchange(value = "exchange.delay.order.done"),
                    key = "delay")) // 监听的队列
    public void onMessage(Message message) {
        String content = new String(message.getBody());
        System.out.println("监听到的消息："+content);

        //回滚操作
        rollbackOrder(JSONObject.parseObject(content,SeckillStatus.class));
    }


    /*****
     * 订单回滚操作
     * @param seckillStatus
     */
    public void rollbackOrder(SeckillStatus seckillStatus){
        if(seckillStatus==null){
            return;
        }
        //判断Redis中是否存在对应的订单
        SeckillOrder seckillOrder = (SeckillOrder) redisTemplate.boundHashOps("SeckillOrder").get(seckillStatus.getUsername());

        //如果存在，开始回滚
        if(seckillOrder!=null){
            //1.关闭微信支付
            Map<String,String> map = weixinPayService.closePay(seckillStatus.getOrderId().toString());

            if(map.get("return_code").equals("SUCCESS") && map.get("result_code").equals("SUCCESS")){
                //2.删除用户订单
                redisTemplate.boundHashOps("SeckillOrder").delete(seckillOrder.getUserId());

                //3.查询出商品数据
                SeckillGoods goods = (SeckillGoods) redisTemplate.boundHashOps("SeckillGoods_"+seckillStatus.getTime()).get(seckillStatus.getGoodsId());
                if(goods==null){
                    //数据库中加载数据
                    goods = seckillGoodsMapper.selectByPrimaryKey(seckillStatus.getGoodsId());
                }

                //4.递增库存  incr
                Long seckillGoodsCount = redisTemplate.boundHashOps("SeckillGoodsCount").increment(seckillStatus.getGoodsId(), 1);
                goods.setStockCount(seckillGoodsCount.intValue());

                //5.将商品数据同步到Redis
                redisTemplate.boundHashOps("SeckillGoods_"+seckillStatus.getTime()).put(seckillStatus.getGoodsId(),goods);
                redisTemplate.boundListOps("SeckillGoodsCountList_"+seckillStatus.getGoodsId()).leftPush(seckillStatus.getGoodsId());
                //6.清理用户抢单排队信息
                //清理重复排队标识
                redisTemplate.boundHashOps("UserQueueCount").delete(seckillStatus.getUsername());

                //清理排队存储信息
                redisTemplate.boundHashOps("UserQueueStatus").delete(seckillStatus.getUsername());
            }
        }
    }
}
```